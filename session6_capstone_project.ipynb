{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 (4-6h): ìº¡ìŠ¤í†¤ ì‹¤ìŠµ & ìš´ì˜ ê³„íš\n",
    "\n",
    "## ì¢…í•© ê³¼ì œ: ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ í’ˆì§ˆ ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "\n",
    "### ì‹œë‚˜ë¦¬ì˜¤\n",
    "ì „ìë¶€í’ˆ ì œì¡° ê³µì¥ì—ì„œ í’ˆì§ˆ ë¶ˆëŸ‰ì„ ì‚¬ì „ì— ì˜ˆì¸¡í•˜ê³ , ê³µì •ì„ ìµœì í™”í•˜ëŠ” AI ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "- ì‹¤ì‹œê°„ ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘\n",
    "- ë¶ˆëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ\n",
    "- ì˜ˆì§€ë³´ì „ ì‹œìŠ¤í…œ í†µí•©\n",
    "- ëŒ€ì‹œë³´ë“œ ë° ì•ŒëŒ ì‹œìŠ¤í…œ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML/DL ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í†µí•© ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartFactoryDataPipeline:\n",
    "    \"\"\"ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ë°ì´í„° íŒŒì´í”„ë¼ì¸\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_sources = {\n",
    "            'sensors': ['temperature', 'pressure', 'humidity', 'vibration', 'current'],\n",
    "            'process': ['speed', 'feed_rate', 'tool_wear', 'cycle_time'],\n",
    "            'quality': ['dimension', 'surface_finish', 'hardness']\n",
    "        }\n",
    "        self.data_buffer = []\n",
    "        self.processed_data = None\n",
    "        \n",
    "    def generate_sensor_data(self, n_samples=1000, anomaly_rate=0.05):\n",
    "        \"\"\"ì„¼ì„œ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # ì •ìƒ ë°ì´í„° ìƒì„±\n",
    "        data = {\n",
    "            'timestamp': pd.date_range(start='2024-01-01', periods=n_samples, freq='1Min'),\n",
    "            'temperature': np.random.normal(75, 5, n_samples),\n",
    "            'pressure': np.random.normal(100, 10, n_samples),\n",
    "            'humidity': np.random.normal(50, 5, n_samples),\n",
    "            'vibration': np.random.normal(2, 0.5, n_samples),\n",
    "            'current': np.random.normal(15, 2, n_samples),\n",
    "            'speed': np.random.normal(1500, 50, n_samples),\n",
    "            'feed_rate': np.random.normal(100, 10, n_samples),\n",
    "            'tool_wear': np.random.uniform(0, 1, n_samples),\n",
    "            'cycle_time': np.random.normal(60, 5, n_samples)\n",
    "        }\n",
    "        \n",
    "        # í’ˆì§ˆ ë°ì´í„°\n",
    "        data['dimension'] = 10 + 0.01 * data['temperature'] - 0.005 * data['pressure'] + np.random.normal(0, 0.1, n_samples)\n",
    "        data['surface_finish'] = 1.5 - 0.001 * data['speed'] + 0.5 * data['tool_wear'] + np.random.normal(0, 0.05, n_samples)\n",
    "        data['hardness'] = 60 + 0.1 * data['temperature'] - 0.02 * data['cycle_time'] + np.random.normal(0, 1, n_samples)\n",
    "        \n",
    "        # ì´ìƒ íŒ¨í„´ ì£¼ì…\n",
    "        n_anomalies = int(n_samples * anomaly_rate)\n",
    "        anomaly_indices = np.random.choice(n_samples, n_anomalies, replace=False)\n",
    "        \n",
    "        # ë‹¤ì–‘í•œ ì´ìƒ íŒ¨í„´\n",
    "        for idx in anomaly_indices:\n",
    "            anomaly_type = np.random.choice(['temperature', 'vibration', 'tool_wear', 'multi'])\n",
    "            \n",
    "            if anomaly_type == 'temperature':\n",
    "                data['temperature'][idx] += np.random.choice([-20, 20])\n",
    "            elif anomaly_type == 'vibration':\n",
    "                data['vibration'][idx] *= np.random.uniform(3, 5)\n",
    "            elif anomaly_type == 'tool_wear':\n",
    "                data['tool_wear'][idx] = min(1.0, data['tool_wear'][idx] * 2)\n",
    "            else:  # multi\n",
    "                data['temperature'][idx] += 15\n",
    "                data['vibration'][idx] *= 2\n",
    "                data['pressure'][idx] -= 20\n",
    "        \n",
    "        # ë¶ˆëŸ‰ ë¼ë²¨ ìƒì„± (ê·œê²© ê¸°ë°˜)\n",
    "        defects = (\n",
    "            (np.abs(data['dimension'] - 10) > 0.5) |\n",
    "            (data['surface_finish'] > 2.0) |\n",
    "            (data['hardness'] < 55) | (data['hardness'] > 65)\n",
    "        )\n",
    "        \n",
    "        data['defect'] = defects.astype(int)\n",
    "        data['anomaly'] = np.zeros(n_samples)\n",
    "        data['anomaly'][anomaly_indices] = 1\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def extract_features(self, df, window_size=10):\n",
    "        \"\"\"íŠ¹ì§• ì¶”ì¶œ (í†µê³„ì  íŠ¹ì§• + ì‹œê³„ì—´ íŠ¹ì§•)\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # Rolling window íŠ¹ì§•\n",
    "        sensor_cols = ['temperature', 'pressure', 'vibration', 'current']\n",
    "        \n",
    "        for col in sensor_cols:\n",
    "            features[f'{col}_rolling_mean'] = df[col].rolling(window=window_size, min_periods=1).mean()\n",
    "            features[f'{col}_rolling_std'] = df[col].rolling(window=window_size, min_periods=1).std()\n",
    "            features[f'{col}_rolling_max'] = df[col].rolling(window=window_size, min_periods=1).max()\n",
    "            features[f'{col}_rolling_min'] = df[col].rolling(window=window_size, min_periods=1).min()\n",
    "        \n",
    "        # ë³€í™”ìœ¨ íŠ¹ì§•\n",
    "        for col in sensor_cols:\n",
    "            features[f'{col}_diff'] = df[col].diff()\n",
    "            features[f'{col}_pct_change'] = df[col].pct_change()\n",
    "        \n",
    "        # ìƒí˜¸ì‘ìš© íŠ¹ì§•\n",
    "        features['temp_pressure_ratio'] = features['temperature'] / (features['pressure'] + 1)\n",
    "        features['vibration_current_product'] = features['vibration'] * features['current']\n",
    "        features['efficiency'] = features['speed'] / (features['cycle_time'] + 1)\n",
    "        \n",
    "        # NaN ì²˜ë¦¬\n",
    "        features = features.fillna(method='ffill').fillna(0)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def create_train_test_split(self, df, test_size=0.2):\n",
    "        \"\"\"ì‹œê³„ì—´ì„ ê³ ë ¤í•œ í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• \"\"\"\n",
    "        # ì‹œê°„ ìˆœì„œ ìœ ì§€\n",
    "        split_index = int(len(df) * (1 - test_size))\n",
    "        \n",
    "        train_df = df.iloc[:split_index]\n",
    "        test_df = df.iloc[split_index:]\n",
    "        \n",
    "        return train_df, test_df\n",
    "\n",
    "# ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "pipeline = SmartFactoryDataPipeline()\n",
    "\n",
    "# ë°ì´í„° ìƒì„±\n",
    "print(\"Generating manufacturing data...\")\n",
    "raw_data = pipeline.generate_sensor_data(n_samples=2000, anomaly_rate=0.05)\n",
    "\n",
    "# íŠ¹ì§• ì¶”ì¶œ\n",
    "print(\"Extracting features...\")\n",
    "feature_data = pipeline.extract_features(raw_data)\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "train_data, test_data = pipeline.create_train_test_split(feature_data)\n",
    "\n",
    "print(f\"\\nData Pipeline Summary:\")\n",
    "print(f\"  Total samples: {len(raw_data)}\")\n",
    "print(f\"  Features: {len(feature_data.columns)}\")\n",
    "print(f\"  Training samples: {len(train_data)}\")\n",
    "print(f\"  Test samples: {len(test_data)}\")\n",
    "print(f\"  Defect rate: {raw_data['defect'].mean():.2%}\")\n",
    "print(f\"  Anomaly rate: {raw_data['anomaly'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. í†µí•© AI ëª¨ë¸ ì‹œìŠ¤í…œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegratedAISystem:\n",
    "    \"\"\"í†µí•© AI ì‹œìŠ¤í…œ (í’ˆì§ˆ ì˜ˆì¸¡ + ì´ìƒ íƒì§€ + ì˜ˆì§€ë³´ì „)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'quality_predictor': None,\n",
    "            'anomaly_detector': None,\n",
    "            'maintenance_predictor': None\n",
    "        }\n",
    "        self.scalers = {}\n",
    "        self.performance_metrics = {}\n",
    "        \n",
    "    def train_quality_predictor(self, X_train, y_train):\n",
    "        \"\"\"í’ˆì§ˆ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        print(\"Training Quality Predictor...\")\n",
    "        \n",
    "        # ìŠ¤ì¼€ì¼ë§\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_train)\n",
    "        self.scalers['quality'] = scaler\n",
    "        \n",
    "        # Random Forest ëª¨ë¸\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        model.fit(X_scaled, y_train)\n",
    "        self.models['quality_predictor'] = model\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False).head(10)\n",
    "        \n",
    "        print(\"  Top 10 Important Features:\")\n",
    "        for _, row in feature_importance.iterrows():\n",
    "            print(f\"    {row['feature']}: {row['importance']:.4f}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_anomaly_detector(self, X_normal):\n",
    "        \"\"\"ì´ìƒ íƒì§€ ëª¨ë¸ í•™ìŠµ\"\"\"\n",
    "        print(\"\\nTraining Anomaly Detector...\")\n",
    "        \n",
    "        # ìŠ¤ì¼€ì¼ë§\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_normal)\n",
    "        self.scalers['anomaly'] = scaler\n",
    "        \n",
    "        # Isolation Forest\n",
    "        model = IsolationForest(\n",
    "            contamination=0.05,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        model.fit(X_scaled)\n",
    "        self.models['anomaly_detector'] = model\n",
    "        \n",
    "        # ì´ìƒ ì ìˆ˜ ë¶„í¬\n",
    "        anomaly_scores = model.score_samples(X_scaled)\n",
    "        print(f\"  Anomaly score range: [{np.min(anomaly_scores):.3f}, {np.max(anomaly_scores):.3f}]\")\n",
    "        print(f\"  Anomaly threshold: {np.percentile(anomaly_scores, 5):.3f}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_maintenance_predictor(self, X_train, y_maintenance):\n",
    "        \"\"\"ì˜ˆì§€ë³´ì „ ëª¨ë¸ (RUL ì˜ˆì¸¡)\"\"\"\n",
    "        print(\"\\nTraining Maintenance Predictor...\")\n",
    "        \n",
    "        # ê°„ë‹¨í•œ RUL (Remaining Useful Life) ì˜ˆì¸¡ ëª¨ë¸\n",
    "        # Tool wearë¥¼ ê¸°ë°˜ìœ¼ë¡œ RUL ê³„ì‚°\n",
    "        class MaintenanceModel:\n",
    "            def __init__(self):\n",
    "                self.threshold = 0.8\n",
    "                \n",
    "            def predict_rul(self, tool_wear, vibration):\n",
    "                # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ RUL ì˜ˆì¸¡\n",
    "                base_rul = (1.0 - tool_wear) * 100  # ê¸°ë³¸ RUL (ì‹œê°„)\n",
    "                \n",
    "                # ì§„ë™ì´ ë†’ìœ¼ë©´ RUL ê°ì†Œ\n",
    "                vibration_factor = np.clip(1.0 - (vibration - 2.0) / 3.0, 0.5, 1.0)\n",
    "                \n",
    "                rul = base_rul * vibration_factor\n",
    "                \n",
    "                return rul\n",
    "            \n",
    "            def predict_maintenance(self, tool_wear, vibration):\n",
    "                rul = self.predict_rul(tool_wear, vibration)\n",
    "                \n",
    "                if rul < 10:\n",
    "                    return 'urgent'\n",
    "                elif rul < 30:\n",
    "                    return 'scheduled'\n",
    "                else:\n",
    "                    return 'normal'\n",
    "        \n",
    "        model = MaintenanceModel()\n",
    "        self.models['maintenance_predictor'] = model\n",
    "        \n",
    "        print(\"  Maintenance model configured\")\n",
    "        print(\"  RUL categories: urgent (<10h), scheduled (10-30h), normal (>30h)\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def integrated_prediction(self, X):\n",
    "        \"\"\"í†µí•© ì˜ˆì¸¡ ìˆ˜í–‰\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # 1. í’ˆì§ˆ ì˜ˆì¸¡\n",
    "        if self.models['quality_predictor'] and 'quality' in self.scalers:\n",
    "            X_scaled = self.scalers['quality'].transform(X)\n",
    "            quality_pred = self.models['quality_predictor'].predict(X_scaled)\n",
    "            quality_proba = self.models['quality_predictor'].predict_proba(X_scaled)\n",
    "            results['quality_prediction'] = quality_pred\n",
    "            results['quality_probability'] = quality_proba\n",
    "        \n",
    "        # 2. ì´ìƒ íƒì§€\n",
    "        if self.models['anomaly_detector'] and 'anomaly' in self.scalers:\n",
    "            X_scaled = self.scalers['anomaly'].transform(X)\n",
    "            anomaly_pred = self.models['anomaly_detector'].predict(X_scaled)\n",
    "            anomaly_score = self.models['anomaly_detector'].score_samples(X_scaled)\n",
    "            results['anomaly_detection'] = (anomaly_pred == -1).astype(int)\n",
    "            results['anomaly_score'] = anomaly_score\n",
    "        \n",
    "        # 3. ì˜ˆì§€ë³´ì „\n",
    "        if self.models['maintenance_predictor']:\n",
    "            if 'tool_wear' in X.columns and 'vibration' in X.columns:\n",
    "                maintenance_status = []\n",
    "                rul_values = []\n",
    "                \n",
    "                for _, row in X.iterrows():\n",
    "                    rul = self.models['maintenance_predictor'].predict_rul(\n",
    "                        row['tool_wear'], row['vibration']\n",
    "                    )\n",
    "                    status = self.models['maintenance_predictor'].predict_maintenance(\n",
    "                        row['tool_wear'], row['vibration']\n",
    "                    )\n",
    "                    rul_values.append(rul)\n",
    "                    maintenance_status.append(status)\n",
    "                \n",
    "                results['maintenance_status'] = maintenance_status\n",
    "                results['rul_hours'] = rul_values\n",
    "        \n",
    "        return results\n",
    "\n",
    "# AI ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "ai_system = IntegratedAISystem()\n",
    "\n",
    "# íŠ¹ì§• ì„ íƒ\n",
    "feature_cols = [col for col in train_data.columns \n",
    "                if col not in ['timestamp', 'defect', 'anomaly']]\n",
    "\n",
    "X_train = train_data[feature_cols]\n",
    "y_train = train_data['defect']\n",
    "\n",
    "X_test = test_data[feature_cols]\n",
    "y_test = test_data['defect']\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING INTEGRATED AI SYSTEM\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. í’ˆì§ˆ ì˜ˆì¸¡ ëª¨ë¸\n",
    "quality_model = ai_system.train_quality_predictor(X_train, y_train)\n",
    "\n",
    "# 2. ì´ìƒ íƒì§€ ëª¨ë¸ (ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš©)\n",
    "X_normal = X_train[train_data['anomaly'] == 0]\n",
    "anomaly_model = ai_system.train_anomaly_detector(X_normal)\n",
    "\n",
    "# 3. ì˜ˆì§€ë³´ì „ ëª¨ë¸\n",
    "maintenance_model = ai_system.train_maintenance_predictor(X_train, None)\n",
    "\n",
    "print(\"\\nâœ… All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. í†µí•© ëŒ€ì‹œë³´ë“œ ë° ëª¨ë‹ˆí„°ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartFactoryDashboard:\n",
    "    \"\"\"ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ í†µí•© ëŒ€ì‹œë³´ë“œ\"\"\"\n",
    "    \n",
    "    def __init__(self, ai_system):\n",
    "        self.ai_system = ai_system\n",
    "        self.kpi_metrics = {}\n",
    "        self.alerts = []\n",
    "        \n",
    "    def calculate_kpis(self, predictions, actuals=None):\n",
    "        \"\"\"ì£¼ìš” KPI ê³„ì‚°\"\"\"\n",
    "        \n",
    "        # í’ˆì§ˆ KPI\n",
    "        quality_pred = predictions.get('quality_prediction', [])\n",
    "        if len(quality_pred) > 0:\n",
    "            self.kpi_metrics['defect_rate'] = np.mean(quality_pred)\n",
    "            self.kpi_metrics['quality_score'] = 100 * (1 - np.mean(quality_pred))\n",
    "        \n",
    "        # ì´ìƒ íƒì§€ KPI\n",
    "        anomaly_pred = predictions.get('anomaly_detection', [])\n",
    "        if len(anomaly_pred) > 0:\n",
    "            self.kpi_metrics['anomaly_rate'] = np.mean(anomaly_pred)\n",
    "            self.kpi_metrics['system_health'] = 100 * (1 - np.mean(anomaly_pred))\n",
    "        \n",
    "        # ì˜ˆì§€ë³´ì „ KPI\n",
    "        maintenance_status = predictions.get('maintenance_status', [])\n",
    "        if maintenance_status:\n",
    "            urgent_count = sum(1 for s in maintenance_status if s == 'urgent')\n",
    "            scheduled_count = sum(1 for s in maintenance_status if s == 'scheduled')\n",
    "            \n",
    "            self.kpi_metrics['urgent_maintenance'] = urgent_count\n",
    "            self.kpi_metrics['scheduled_maintenance'] = scheduled_count\n",
    "            self.kpi_metrics['maintenance_score'] = 100 * (1 - urgent_count / len(maintenance_status))\n",
    "        \n",
    "        # RUL í†µê³„\n",
    "        rul_values = predictions.get('rul_hours', [])\n",
    "        if rul_values:\n",
    "            self.kpi_metrics['avg_rul'] = np.mean(rul_values)\n",
    "            self.kpi_metrics['min_rul'] = np.min(rul_values)\n",
    "        \n",
    "        # OEE ê³„ì‚° (Overall Equipment Effectiveness)\n",
    "        availability = 0.95  # ê°€ì •\n",
    "        performance = 0.90   # ê°€ì •\n",
    "        quality = self.kpi_metrics.get('quality_score', 100) / 100\n",
    "        self.kpi_metrics['oee'] = availability * performance * quality * 100\n",
    "        \n",
    "        return self.kpi_metrics\n",
    "    \n",
    "    def generate_alerts(self, predictions, data):\n",
    "        \"\"\"ê²½ë³´ ìƒì„±\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        # í’ˆì§ˆ ê²½ë³´\n",
    "        quality_pred = predictions.get('quality_prediction', [])\n",
    "        for i, pred in enumerate(quality_pred):\n",
    "            if pred == 1:  # ë¶ˆëŸ‰ ì˜ˆì¸¡\n",
    "                alerts.append({\n",
    "                    'timestamp': datetime.now(),\n",
    "                    'type': 'QUALITY',\n",
    "                    'severity': 'HIGH',\n",
    "                    'message': f'Defect predicted at index {i}',\n",
    "                    'action': 'Inspect product immediately'\n",
    "                })\n",
    "        \n",
    "        # ì´ìƒ ê²½ë³´\n",
    "        anomaly_pred = predictions.get('anomaly_detection', [])\n",
    "        anomaly_scores = predictions.get('anomaly_score', [])\n",
    "        for i, (pred, score) in enumerate(zip(anomaly_pred, anomaly_scores)):\n",
    "            if pred == 1:\n",
    "                alerts.append({\n",
    "                    'timestamp': datetime.now(),\n",
    "                    'type': 'ANOMALY',\n",
    "                    'severity': 'CRITICAL' if score < -0.5 else 'HIGH',\n",
    "                    'message': f'Anomaly detected (score: {score:.3f})',\n",
    "                    'action': 'Check sensor readings and equipment'\n",
    "                })\n",
    "        \n",
    "        # ìœ ì§€ë³´ìˆ˜ ê²½ë³´\n",
    "        maintenance_status = predictions.get('maintenance_status', [])\n",
    "        for i, status in enumerate(maintenance_status):\n",
    "            if status == 'urgent':\n",
    "                alerts.append({\n",
    "                    'timestamp': datetime.now(),\n",
    "                    'type': 'MAINTENANCE',\n",
    "                    'severity': 'CRITICAL',\n",
    "                    'message': f'Urgent maintenance required',\n",
    "                    'action': 'Schedule immediate maintenance'\n",
    "                })\n",
    "            elif status == 'scheduled':\n",
    "                alerts.append({\n",
    "                    'timestamp': datetime.now(),\n",
    "                    'type': 'MAINTENANCE',\n",
    "                    'severity': 'MEDIUM',\n",
    "                    'message': f'Maintenance needed soon',\n",
    "                    'action': 'Schedule maintenance within 24 hours'\n",
    "                })\n",
    "        \n",
    "        self.alerts.extend(alerts)\n",
    "        return alerts\n",
    "    \n",
    "    def visualize_dashboard(self, data, predictions):\n",
    "        \"\"\"ëŒ€ì‹œë³´ë“œ ì‹œê°í™”\"\"\"\n",
    "        fig = plt.figure(figsize=(16, 10))\n",
    "        \n",
    "        # KPI ì¹´ë“œ (ìƒë‹¨)\n",
    "        gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # OEE\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        ax1.text(0.5, 0.7, f\"{self.kpi_metrics.get('oee', 0):.1f}%\", \n",
    "                ha='center', va='center', fontsize=24, fontweight='bold')\n",
    "        ax1.text(0.5, 0.3, 'OEE', ha='center', va='center', fontsize=12)\n",
    "        ax1.set_xlim(0, 1)\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Quality Score\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        ax2.text(0.5, 0.7, f\"{self.kpi_metrics.get('quality_score', 0):.1f}%\", \n",
    "                ha='center', va='center', fontsize=24, fontweight='bold',\n",
    "                color='green' if self.kpi_metrics.get('quality_score', 0) > 95 else 'orange')\n",
    "        ax2.text(0.5, 0.3, 'Quality Score', ha='center', va='center', fontsize=12)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # System Health\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        ax3.text(0.5, 0.7, f\"{self.kpi_metrics.get('system_health', 0):.1f}%\", \n",
    "                ha='center', va='center', fontsize=24, fontweight='bold',\n",
    "                color='green' if self.kpi_metrics.get('system_health', 0) > 90 else 'red')\n",
    "        ax3.text(0.5, 0.3, 'System Health', ha='center', va='center', fontsize=12)\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        # Avg RUL\n",
    "        ax4 = fig.add_subplot(gs[0, 3])\n",
    "        ax4.text(0.5, 0.7, f\"{self.kpi_metrics.get('avg_rul', 0):.0f}h\", \n",
    "                ha='center', va='center', fontsize=24, fontweight='bold')\n",
    "        ax4.text(0.5, 0.3, 'Avg RUL', ha='center', va='center', fontsize=12)\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        # ì„¼ì„œ ë°ì´í„° íŠ¸ë Œë“œ\n",
    "        ax5 = fig.add_subplot(gs[1, :])\n",
    "        sensor_cols = ['temperature', 'pressure', 'vibration']\n",
    "        for col in sensor_cols:\n",
    "            if col in data.columns:\n",
    "                ax5.plot(data.index[-100:], data[col].iloc[-100:], label=col, alpha=0.7)\n",
    "        ax5.set_xlabel('Time')\n",
    "        ax5.set_ylabel('Sensor Value')\n",
    "        ax5.set_title('Sensor Data Trends (Last 100 samples)')\n",
    "        ax5.legend()\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "        \n",
    "        # ì˜ˆì¸¡ ê²°ê³¼\n",
    "        ax6 = fig.add_subplot(gs[2, :2])\n",
    "        quality_pred = predictions.get('quality_prediction', [])\n",
    "        if len(quality_pred) > 0:\n",
    "            ax6.plot(quality_pred[-100:], 'r-', alpha=0.5, label='Defect Prediction')\n",
    "            ax6.fill_between(range(len(quality_pred[-100:])), \n",
    "                            0, quality_pred[-100:], alpha=0.3, color='red')\n",
    "        ax6.set_xlabel('Sample')\n",
    "        ax6.set_ylabel('Defect Probability')\n",
    "        ax6.set_title('Quality Predictions')\n",
    "        ax6.legend()\n",
    "        ax6.grid(True, alpha=0.3)\n",
    "        \n",
    "        # ì•ŒëŒ íˆìŠ¤í† ë¦¬\n",
    "        ax7 = fig.add_subplot(gs[2, 2:])\n",
    "        if self.alerts:\n",
    "            alert_types = [a['type'] for a in self.alerts[-20:]]\n",
    "            alert_counts = pd.Series(alert_types).value_counts()\n",
    "            colors = {'QUALITY': 'orange', 'ANOMALY': 'red', 'MAINTENANCE': 'yellow'}\n",
    "            bar_colors = [colors.get(t, 'gray') for t in alert_counts.index]\n",
    "            ax7.bar(alert_counts.index, alert_counts.values, color=bar_colors)\n",
    "        ax7.set_xlabel('Alert Type')\n",
    "        ax7.set_ylabel('Count')\n",
    "        ax7.set_title('Recent Alerts (Last 20)')\n",
    "        ax7.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle('Smart Factory Dashboard', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ëŒ€ì‹œë³´ë“œ ì‹¤í–‰\n",
    "dashboard = SmartFactoryDashboard(ai_system)\n",
    "\n",
    "# í†µí•© ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INTEGRATED PREDICTION & MONITORING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "predictions = ai_system.integrated_prediction(X_test)\n",
    "\n",
    "# KPI ê³„ì‚°\n",
    "kpis = dashboard.calculate_kpis(predictions)\n",
    "print(\"\\nKey Performance Indicators:\")\n",
    "for key, value in kpis.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# ì•ŒëŒ ìƒì„±\n",
    "alerts = dashboard.generate_alerts(predictions, test_data)\n",
    "print(f\"\\nAlerts Generated: {len(alerts)}\")\n",
    "if alerts:\n",
    "    print(\"  Recent Alerts:\")\n",
    "    for alert in alerts[:5]:\n",
    "        print(f\"    [{alert['severity']}] {alert['type']}: {alert['message']}\")\n",
    "\n",
    "# ëŒ€ì‹œë³´ë“œ ì‹œê°í™”\n",
    "dashboard.visualize_dashboard(test_data, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ìš´ì˜ ê³„íš ìˆ˜ë¦½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationalPlan:\n",
    "    \"\"\"AI ì‹œìŠ¤í…œ ìš´ì˜ ê³„íš\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.deployment_plan = None\n",
    "        self.maintenance_schedule = None\n",
    "        self.monitoring_plan = None\n",
    "        self.training_plan = None\n",
    "        \n",
    "    def create_deployment_plan(self):\n",
    "        \"\"\"ë°°í¬ ê³„íš ìˆ˜ë¦½\"\"\"\n",
    "        self.deployment_plan = {\n",
    "            'phase1': {\n",
    "                'name': 'Pilot Testing',\n",
    "                'duration': '2 weeks',\n",
    "                'scope': 'Single production line',\n",
    "                'activities': [\n",
    "                    'Install sensors and edge devices',\n",
    "                    'Configure data pipeline',\n",
    "                    'Deploy AI models in shadow mode',\n",
    "                    'Validate predictions against actual results'\n",
    "                ],\n",
    "                'success_criteria': {\n",
    "                    'accuracy': '>90%',\n",
    "                    'false_positive_rate': '<5%',\n",
    "                    'system_uptime': '>99%'\n",
    "                }\n",
    "            },\n",
    "            'phase2': {\n",
    "                'name': 'Limited Production',\n",
    "                'duration': '1 month',\n",
    "                'scope': '3 production lines',\n",
    "                'activities': [\n",
    "                    'Scale to multiple lines',\n",
    "                    'Enable real-time alerts',\n",
    "                    'Train operators',\n",
    "                    'Fine-tune models'\n",
    "                ]\n",
    "            },\n",
    "            'phase3': {\n",
    "                'name': 'Full Production',\n",
    "                'duration': 'Ongoing',\n",
    "                'scope': 'All production lines',\n",
    "                'activities': [\n",
    "                    'Full deployment',\n",
    "                    'Integration with MES/ERP',\n",
    "                    'Automated decision making',\n",
    "                    'Continuous improvement'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return self.deployment_plan\n",
    "    \n",
    "    def create_monitoring_plan(self):\n",
    "        \"\"\"ëª¨ë‹ˆí„°ë§ ê³„íš ìˆ˜ë¦½\"\"\"\n",
    "        self.monitoring_plan = {\n",
    "            'real_time_monitoring': {\n",
    "                'metrics': [\n",
    "                    'Prediction accuracy',\n",
    "                    'Inference latency',\n",
    "                    'Data quality',\n",
    "                    'System health'\n",
    "                ],\n",
    "                'tools': ['Grafana', 'Prometheus', 'ELK Stack'],\n",
    "                'alert_channels': ['Email', 'SMS', 'Slack']\n",
    "            },\n",
    "            'model_monitoring': {\n",
    "                'drift_detection': 'Weekly',\n",
    "                'performance_evaluation': 'Daily',\n",
    "                'feature_importance_check': 'Monthly'\n",
    "            },\n",
    "            'business_monitoring': {\n",
    "                'kpi_review': 'Weekly',\n",
    "                'roi_calculation': 'Monthly',\n",
    "                'stakeholder_reporting': 'Monthly'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return self.monitoring_plan\n",
    "    \n",
    "    def create_maintenance_schedule(self):\n",
    "        \"\"\"ìœ ì§€ë³´ìˆ˜ ì¼ì • ìˆ˜ë¦½\"\"\"\n",
    "        self.maintenance_schedule = {\n",
    "            'daily': [\n",
    "                'Check system health dashboard',\n",
    "                'Review alert logs',\n",
    "                'Validate data pipeline'\n",
    "            ],\n",
    "            'weekly': [\n",
    "                'Model performance review',\n",
    "                'Data quality assessment',\n",
    "                'Backup model artifacts',\n",
    "                'Update documentation'\n",
    "            ],\n",
    "            'monthly': [\n",
    "                'Model retraining evaluation',\n",
    "                'Feature engineering review',\n",
    "                'System optimization',\n",
    "                'Security audit'\n",
    "            ],\n",
    "            'quarterly': [\n",
    "                'Major model updates',\n",
    "                'Infrastructure scaling review',\n",
    "                'Disaster recovery test',\n",
    "                'Compliance check'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return self.maintenance_schedule\n",
    "    \n",
    "    def create_training_plan(self):\n",
    "        \"\"\"êµìœ¡ ê³„íš ìˆ˜ë¦½\"\"\"\n",
    "        self.training_plan = {\n",
    "            'operators': {\n",
    "                'duration': '2 days',\n",
    "                'topics': [\n",
    "                    'Dashboard navigation',\n",
    "                    'Alert interpretation',\n",
    "                    'Basic troubleshooting',\n",
    "                    'Data entry procedures'\n",
    "                ]\n",
    "            },\n",
    "            'engineers': {\n",
    "                'duration': '1 week',\n",
    "                'topics': [\n",
    "                    'System architecture',\n",
    "                    'Model interpretation',\n",
    "                    'Parameter tuning',\n",
    "                    'Advanced troubleshooting'\n",
    "                ]\n",
    "            },\n",
    "            'data_scientists': {\n",
    "                'duration': '2 weeks',\n",
    "                'topics': [\n",
    "                    'Model development',\n",
    "                    'Feature engineering',\n",
    "                    'MLOps practices',\n",
    "                    'Continuous improvement'\n",
    "                ]\n",
    "            },\n",
    "            'management': {\n",
    "                'duration': '1 day',\n",
    "                'topics': [\n",
    "                    'KPI interpretation',\n",
    "                    'ROI analysis',\n",
    "                    'Strategic planning',\n",
    "                    'Change management'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return self.training_plan\n",
    "    \n",
    "    def calculate_roi(self, investment=100000, monthly_savings=15000, months=24):\n",
    "        \"\"\"ROI ê³„ì‚°\"\"\"\n",
    "        total_savings = monthly_savings * months\n",
    "        roi = ((total_savings - investment) / investment) * 100\n",
    "        payback_period = investment / monthly_savings\n",
    "        \n",
    "        return {\n",
    "            'initial_investment': investment,\n",
    "            'monthly_savings': monthly_savings,\n",
    "            'total_savings': total_savings,\n",
    "            'roi_percentage': roi,\n",
    "            'payback_months': payback_period\n",
    "        }\n",
    "\n",
    "# ìš´ì˜ ê³„íš ìˆ˜ë¦½\n",
    "ops_plan = OperationalPlan()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OPERATIONAL PLANNING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ë°°í¬ ê³„íš\n",
    "deployment_plan = ops_plan.create_deployment_plan()\n",
    "print(\"\\nğŸ“‹ Deployment Plan:\")\n",
    "for phase, details in deployment_plan.items():\n",
    "    print(f\"\\n  {phase.upper()}: {details['name']}\")\n",
    "    print(f\"    Duration: {details['duration']}\")\n",
    "    print(f\"    Scope: {details['scope']}\")\n",
    "\n",
    "# ëª¨ë‹ˆí„°ë§ ê³„íš\n",
    "monitoring_plan = ops_plan.create_monitoring_plan()\n",
    "print(\"\\nğŸ“Š Monitoring Plan:\")\n",
    "for category, details in monitoring_plan.items():\n",
    "    print(f\"  {category.replace('_', ' ').title()}:\")\n",
    "    for key, value in details.items():\n",
    "        if isinstance(value, list):\n",
    "            print(f\"    {key}: {', '.join(value)}\")\n",
    "        else:\n",
    "            print(f\"    {key}: {value}\")\n",
    "\n",
    "# ROI ê³„ì‚°\n",
    "roi_calc = ops_plan.calculate_roi(\n",
    "    investment=150000,\n",
    "    monthly_savings=25000,\n",
    "    months=24\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ’° ROI Analysis:\")\n",
    "print(f\"  Initial Investment: ${roi_calc['initial_investment']:,}\")\n",
    "print(f\"  Monthly Savings: ${roi_calc['monthly_savings']:,}\")\n",
    "print(f\"  Total Savings (24 months): ${roi_calc['total_savings']:,}\")\n",
    "print(f\"  ROI: {roi_calc['roi_percentage']:.1f}%\")\n",
    "print(f\"  Payback Period: {roi_calc['payback_months']:.1f} months\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ì²´í¬ë¦¬ìŠ¤íŠ¸ ë° ë‹¤ìŒ ë‹¨ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "checklist = {\n",
    "    'Data Infrastructure': [\n",
    "        'âœ“ Sensor data collection pipeline',\n",
    "        'âœ“ Data quality validation',\n",
    "        'âœ“ Feature engineering pipeline',\n",
    "        'âœ“ Data storage and backup'\n",
    "    ],\n",
    "    'AI Models': [\n",
    "        'âœ“ Quality prediction model',\n",
    "        'âœ“ Anomaly detection model',\n",
    "        'âœ“ Predictive maintenance model',\n",
    "        'âœ“ Model versioning system'\n",
    "    ],\n",
    "    'Deployment': [\n",
    "        'âœ“ API endpoints',\n",
    "        'âœ“ Model serving infrastructure',\n",
    "        'â–¡ Container orchestration',\n",
    "        'â–¡ Load balancing'\n",
    "    ],\n",
    "    'Monitoring': [\n",
    "        'âœ“ Real-time dashboard',\n",
    "        'âœ“ Alert system',\n",
    "        'âœ“ KPI tracking',\n",
    "        'â–¡ Drift detection automation'\n",
    "    ],\n",
    "    'Operations': [\n",
    "        'âœ“ Deployment plan',\n",
    "        'âœ“ Maintenance schedule',\n",
    "        'â–¡ Training materials',\n",
    "        'â–¡ Documentation'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"IMPLEMENTATION CHECKLIST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for category, items in checklist.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for item in items:\n",
    "        print(f\"  {item}\")\n",
    "\n",
    "# ë‹¤ìŒ ë‹¨ê³„\n",
    "next_steps = [\n",
    "    \"1. Pilot deployment on selected production line\",\n",
    "    \"2. Collect feedback from operators and engineers\",\n",
    "    \"3. Fine-tune models based on real production data\",\n",
    "    \"4. Develop automated retraining pipeline\",\n",
    "    \"5. Scale to additional production lines\",\n",
    "    \"6. Integrate with existing MES/ERP systems\",\n",
    "    \"7. Implement advanced features (multi-variate analysis, root cause analysis)\",\n",
    "    \"8. Establish continuous improvement process\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"  {step}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ¯ PROJECT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(\"\"\"\n",
    "Smart Factory AI System Successfully Designed!\n",
    "\n",
    "âœ… Integrated AI system with 3 core models\n",
    "âœ… Real-time monitoring dashboard\n",
    "âœ… Comprehensive alert system\n",
    "âœ… Operational planning framework\n",
    "âœ… ROI analysis completed\n",
    "\n",
    "Ready for pilot deployment!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹¤ìŠµ ê³¼ì œ\n",
    "\n",
    "### ê°œì¸ í”„ë¡œì íŠ¸ ì •ì˜\n",
    "1. **ë¬¸ì œ ì •ì˜**: ìì‹ ì˜ ì œì¡° í˜„ì¥ì—ì„œ í•´ê²°í•˜ê³ ì í•˜ëŠ” êµ¬ì²´ì ì¸ ë¬¸ì œ ì„ íƒ\n",
    "2. **ë°ì´í„° ìˆ˜ì§‘ ê³„íš**: í•„ìš”í•œ ë°ì´í„°ì™€ ìˆ˜ì§‘ ë°©ë²• ì •ì˜\n",
    "3. **ëª¨ë¸ ì„ íƒ**: ì í•©í•œ AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ì„ íƒ\n",
    "4. **ì„±ê³µ ì§€í‘œ**: ì¸¡ì • ê°€ëŠ¥í•œ KPI ì •ì˜\n",
    "5. **êµ¬í˜„ ë¡œë“œë§µ**: 3-6ê°œì›” êµ¬í˜„ ê³„íš ìˆ˜ë¦½\n",
    "\n",
    "### íŒ€ í”„ë¡œì íŠ¸\n",
    "1. **Cross-functional íŒ€ êµ¬ì„±**: IT, ìƒì‚°, í’ˆì§ˆ ë¶€ì„œ í˜‘ì—…\n",
    "2. **PoC í”„ë¡œì íŠ¸ ì„ ì •**: Quick-win ê°€ëŠ¥í•œ ê³¼ì œ ì„ íƒ\n",
    "3. **ë¦¬ìŠ¤í¬ ë¶„ì„**: ê¸°ìˆ ì /ìš´ì˜ì  ë¦¬ìŠ¤í¬ ì‹ë³„\n",
    "4. **ë³€ê²½ ê´€ë¦¬ ê³„íš**: ì¡°ì§ ë³€í™” ê´€ë¦¬ ì „ëµ\n",
    "\n",
    "### ì§€ì†ì  í•™ìŠµ\n",
    "1. **ê¸°ìˆ  íŠ¸ë Œë“œ ëª¨ë‹ˆí„°ë§**: ìµœì‹  ì œì¡° AI ê¸°ìˆ  ë™í–¥\n",
    "2. **ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬**: ì œì¡° AI ì»¤ë®¤ë‹ˆí‹° í™œë™\n",
    "3. **ë‚´ë¶€ êµìœ¡ í”„ë¡œê·¸ë¨**: ì¡°ì§ ë‚´ AI ì—­ëŸ‰ í™•ì‚°\n",
    "4. **ë²¤ì¹˜ë§ˆí‚¹**: ì„ ì§„ ì‚¬ë¡€ ì—°êµ¬ ë° ì ìš©"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}