{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 (0-2h): 공정 최적화 & 품질 예측\n",
    "\n",
    "## 1. 환경 설정 및 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 설치\n",
    "!pip install -q numpy pandas matplotlib seaborn\n",
    "!pip install -q scikit-learn xgboost lightgbm\n",
    "!pip install -q shap  # SHAP 해석\n",
    "!pip install -q optuna  # 하이퍼파라미터 최적화\n",
    "!pip install -q scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML 라이브러리\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 설명가능 AI\n",
    "import shap\n",
    "\n",
    "# 최적화\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 시각화 설정\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DoE 기초: 공정 파라미터 최적화 실험 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DesignOfExperiments:\n",
    "    \"\"\"실험계획법(DoE) 구현\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.factors = {\n",
    "            'temperature': {'low': 150, 'high': 200, 'unit': '°C'},\n",
    "            'pressure': {'low': 100, 'high': 150, 'unit': 'bar'},\n",
    "            'speed': {'low': 1000, 'high': 1500, 'unit': 'rpm'},\n",
    "            'time': {'low': 30, 'high': 60, 'unit': 'min'}\n",
    "        }\n",
    "        \n",
    "    def full_factorial_design(self, n_levels=2):\n",
    "        \"\"\"완전요인설계 생성\"\"\"\n",
    "        import itertools\n",
    "        \n",
    "        factors_list = list(self.factors.keys())\n",
    "        levels = []\n",
    "        \n",
    "        for factor in factors_list:\n",
    "            if n_levels == 2:\n",
    "                levels.append([self.factors[factor]['low'], \n",
    "                              self.factors[factor]['high']])\n",
    "            else:\n",
    "                # 3수준 이상\n",
    "                low = self.factors[factor]['low']\n",
    "                high = self.factors[factor]['high']\n",
    "                levels.append(np.linspace(low, high, n_levels).tolist())\n",
    "        \n",
    "        # 모든 조합 생성\n",
    "        experiments = list(itertools.product(*levels))\n",
    "        \n",
    "        # DataFrame으로 변환\n",
    "        doe_df = pd.DataFrame(experiments, columns=factors_list)\n",
    "        \n",
    "        return doe_df\n",
    "    \n",
    "    def fractional_factorial_design(self, resolution='III'):\n",
    "        \"\"\"부분요인설계 생성\"\"\"\n",
    "        # 2^(4-1) fractional factorial design\n",
    "        # Resolution III: 주효과는 명확, 2차 상호작용과 혼동\n",
    "        \n",
    "        design_matrix = [\n",
    "            [-1, -1, -1, +1],\n",
    "            [+1, -1, -1, -1],\n",
    "            [-1, +1, -1, -1],\n",
    "            [+1, +1, -1, +1],\n",
    "            [-1, -1, +1, -1],\n",
    "            [+1, -1, +1, +1],\n",
    "            [-1, +1, +1, +1],\n",
    "            [+1, +1, +1, -1]\n",
    "        ]\n",
    "        \n",
    "        # 코드화된 값을 실제 값으로 변환\n",
    "        experiments = []\n",
    "        for row in design_matrix:\n",
    "            exp = []\n",
    "            for i, (factor, levels) in enumerate(self.factors.items()):\n",
    "                if row[i] == -1:\n",
    "                    exp.append(levels['low'])\n",
    "                else:\n",
    "                    exp.append(levels['high'])\n",
    "            experiments.append(exp)\n",
    "        \n",
    "        doe_df = pd.DataFrame(experiments, columns=list(self.factors.keys()))\n",
    "        \n",
    "        return doe_df\n",
    "    \n",
    "    def central_composite_design(self):\n",
    "        \"\"\"중심합성설계 (CCD) 생성\"\"\"\n",
    "        # 2^k factorial + 2k axial points + center points\n",
    "        k = len(self.factors)  # 인자 수\n",
    "        alpha = np.sqrt(k)  # 축점 거리\n",
    "        \n",
    "        experiments = []\n",
    "        factors_list = list(self.factors.keys())\n",
    "        \n",
    "        # Factorial points (corners of cube)\n",
    "        for i in range(2**k):\n",
    "            exp = []\n",
    "            for j in range(k):\n",
    "                if (i >> j) & 1:\n",
    "                    exp.append(self.factors[factors_list[j]]['high'])\n",
    "                else:\n",
    "                    exp.append(self.factors[factors_list[j]]['low'])\n",
    "            experiments.append(exp)\n",
    "        \n",
    "        # Axial points (star points)\n",
    "        for j in range(k):\n",
    "            # +alpha point\n",
    "            exp_plus = []\n",
    "            exp_minus = []\n",
    "            for i in range(k):\n",
    "                center = (self.factors[factors_list[i]]['low'] + \n",
    "                         self.factors[factors_list[i]]['high']) / 2\n",
    "                if i == j:\n",
    "                    range_val = (self.factors[factors_list[i]]['high'] - \n",
    "                                self.factors[factors_list[i]]['low']) / 2\n",
    "                    exp_plus.append(center + alpha * range_val / 2)\n",
    "                    exp_minus.append(center - alpha * range_val / 2)\n",
    "                else:\n",
    "                    exp_plus.append(center)\n",
    "                    exp_minus.append(center)\n",
    "            experiments.append(exp_plus)\n",
    "            experiments.append(exp_minus)\n",
    "        \n",
    "        # Center points\n",
    "        center_point = [(self.factors[f]['low'] + self.factors[f]['high']) / 2 \n",
    "                       for f in factors_list]\n",
    "        for _ in range(3):  # 3 center point replicates\n",
    "            experiments.append(center_point.copy())\n",
    "        \n",
    "        doe_df = pd.DataFrame(experiments, columns=factors_list)\n",
    "        \n",
    "        return doe_df\n",
    "    \n",
    "    def simulate_response(self, doe_df):\n",
    "        \"\"\"응답 시뮬레이션 (실제로는 실험 수행)\"\"\"\n",
    "        # 가상의 품질 응답 함수\n",
    "        # Y = 50 + 0.5*T - 0.3*P + 0.4*S + 0.2*t + noise\n",
    "        # + interaction terms + quadratic terms\n",
    "        \n",
    "        responses = []\n",
    "        \n",
    "        for _, row in doe_df.iterrows():\n",
    "            T = (row['temperature'] - 175) / 25  # 정규화\n",
    "            P = (row['pressure'] - 125) / 25\n",
    "            S = (row['speed'] - 1250) / 250\n",
    "            t = (row['time'] - 45) / 15\n",
    "            \n",
    "            # 주효과\n",
    "            y = 85 + 5*T - 3*P + 4*S + 2*t\n",
    "            \n",
    "            # 상호작용\n",
    "            y += 1.5*T*P - 1*T*S + 0.8*P*S\n",
    "            \n",
    "            # 2차 항\n",
    "            y -= 2*T**2 - 1.5*P**2 - 1*S**2\n",
    "            \n",
    "            # 노이즈\n",
    "            y += np.random.normal(0, 2)\n",
    "            \n",
    "            responses.append(y)\n",
    "        \n",
    "        doe_df['quality'] = responses\n",
    "        \n",
    "        return doe_df\n",
    "\n",
    "# DoE 실행\n",
    "doe = DesignOfExperiments()\n",
    "\n",
    "# 1. 완전요인설계 (2^4 = 16 실험)\n",
    "full_factorial = doe.full_factorial_design(n_levels=2)\n",
    "full_factorial = doe.simulate_response(full_factorial)\n",
    "\n",
    "print(\"Full Factorial Design (2^4)\")\n",
    "print(f\"Number of experiments: {len(full_factorial)}\")\n",
    "print(full_factorial.head())\n",
    "print(f\"\\nQuality range: {full_factorial['quality'].min():.1f} - {full_factorial['quality'].max():.1f}\")\n",
    "\n",
    "# 2. 부분요인설계 (2^(4-1) = 8 실험)\n",
    "fractional_factorial = doe.fractional_factorial_design()\n",
    "fractional_factorial = doe.simulate_response(fractional_factorial)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Fractional Factorial Design (2^(4-1))\")\n",
    "print(f\"Number of experiments: {len(fractional_factorial)}\")\n",
    "print(fractional_factorial.head())\n",
    "\n",
    "# 3. 중심합성설계\n",
    "ccd = doe.central_composite_design()\n",
    "ccd = doe.simulate_response(ccd)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Central Composite Design\")\n",
    "print(f\"Number of experiments: {len(ccd)}\")\n",
    "print(f\"Quality range: {ccd['quality'].min():.1f} - {ccd['quality'].max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 앙상블 모델링: GBM/RandomForest + SHAP 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityPredictionModels:\n",
    "    \"\"\"품질 예측 앙상블 모델\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'RandomForest': RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                random_state=42\n",
    "            ),\n",
    "            'GradientBoosting': GradientBoostingRegressor(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=5,\n",
    "                random_state=42\n",
    "            ),\n",
    "            'XGBoost': xgb.XGBRegressor(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=5,\n",
    "                random_state=42\n",
    "            ),\n",
    "            'LightGBM': lgb.LGBMRegressor(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=5,\n",
    "                random_state=42,\n",
    "                verbose=-1\n",
    "            )\n",
    "        }\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def prepare_data(self, data, target_col='quality'):\n",
    "        \"\"\"데이터 준비\"\"\"\n",
    "        X = data.drop(columns=[target_col])\n",
    "        y = data[target_col]\n",
    "        \n",
    "        # Train/Test 분할\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # 스케일링\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test, X.columns\n",
    "    \n",
    "    def train_and_evaluate(self, X_train, X_test, y_train, y_test, feature_names):\n",
    "        \"\"\"모델 학습 및 평가\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            # 학습\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # 예측\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_test = model.predict(X_test)\n",
    "            \n",
    "            # 평가 메트릭\n",
    "            train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "            test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "            train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "            test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "            train_r2 = r2_score(y_train, y_pred_train)\n",
    "            test_r2 = r2_score(y_test, y_pred_test)\n",
    "            \n",
    "            # 교차 검증\n",
    "            cv_scores = cross_val_score(\n",
    "                model, X_train, y_train, cv=5, \n",
    "                scoring='neg_mean_squared_error'\n",
    "            )\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'train_mse': train_mse,\n",
    "                'test_mse': test_mse,\n",
    "                'train_mae': train_mae,\n",
    "                'test_mae': test_mae,\n",
    "                'train_r2': train_r2,\n",
    "                'test_r2': test_r2,\n",
    "                'cv_mse': -cv_scores.mean(),\n",
    "                'cv_std': cv_scores.std(),\n",
    "                'predictions': y_pred_test\n",
    "            }\n",
    "            \n",
    "            # Feature importance\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                self.feature_importance[name] = pd.DataFrame({\n",
    "                    'feature': feature_names,\n",
    "                    'importance': model.feature_importances_\n",
    "                }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def ensemble_predict(self, models_dict, X_test):\n",
    "        \"\"\"앙상블 예측 (평균)\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for name, result in models_dict.items():\n",
    "            model = result['model']\n",
    "            pred = model.predict(X_test)\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        # 평균 앙상블\n",
    "        ensemble_pred = np.mean(predictions, axis=0)\n",
    "        \n",
    "        return ensemble_pred\n",
    "\n",
    "# 더 많은 데이터 생성 (CCD 사용)\n",
    "large_doe = doe.central_composite_design()\n",
    "# 추가 샘플 생성\n",
    "for _ in range(100):\n",
    "    random_exp = pd.DataFrame([{\n",
    "        'temperature': np.random.uniform(150, 200),\n",
    "        'pressure': np.random.uniform(100, 150),\n",
    "        'speed': np.random.uniform(1000, 1500),\n",
    "        'time': np.random.uniform(30, 60)\n",
    "    }])\n",
    "    large_doe = pd.concat([large_doe, random_exp], ignore_index=True)\n",
    "\n",
    "large_doe = doe.simulate_response(large_doe)\n",
    "\n",
    "# 모델 학습\n",
    "qpm = QualityPredictionModels()\n",
    "X_train, X_test, y_train, y_test, feature_names = qpm.prepare_data(large_doe)\n",
    "\n",
    "print(\"Training ensemble models...\")\n",
    "results = qpm.train_and_evaluate(X_train, X_test, y_train, y_test, feature_names)\n",
    "\n",
    "# 성능 비교\n",
    "performance_df = pd.DataFrame({\n",
    "    model: {\n",
    "        'Train R²': res['train_r2'],\n",
    "        'Test R²': res['test_r2'],\n",
    "        'Train MAE': res['train_mae'],\n",
    "        'Test MAE': res['test_mae'],\n",
    "        'CV MSE': res['cv_mse']\n",
    "    }\n",
    "    for model, res in results.items()\n",
    "}).T\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(performance_df.round(3))\n",
    "\n",
    "# 앙상블 예측\n",
    "ensemble_pred = qpm.ensemble_predict(results, X_test)\n",
    "ensemble_mse = mean_squared_error(y_test, ensemble_pred)\n",
    "ensemble_r2 = r2_score(y_test, ensemble_pred)\n",
    "\n",
    "print(f\"\\nEnsemble Model Performance:\")\n",
    "print(f\"  Test MSE: {ensemble_mse:.3f}\")\n",
    "print(f\"  Test R²: {ensemble_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SHAP을 활용한 모델 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP 분석\n",
    "print(\"Calculating SHAP values...\")\n",
    "\n",
    "# XGBoost 모델 선택 (SHAP과 호환성 좋음)\n",
    "best_model = results['XGBoost']['model']\n",
    "\n",
    "# SHAP explainer 생성\n",
    "explainer = shap.Explainer(best_model, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Feature importance plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)\n",
    "plt.title('SHAP Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for single prediction\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.waterfall_plot(shap_values[0], show=False)\n",
    "plt.title('SHAP Waterfall Plot - Single Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature interactions\n",
    "for i, feature in enumerate(feature_names[:2]):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    shap.scatter_plot(shap_values[:, i], color=shap_values, show=False)\n",
    "    plt.title(f'SHAP Dependence Plot - {feature}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SPC (Statistical Process Control) 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatisticalProcessControl:\n",
    "    \"\"\"통계적 공정 관리 (SPC)\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.control_limits = {}\n",
    "        self.process_capability = {}\n",
    "        \n",
    "    def calculate_control_limits(self, data, n_sigma=3):\n",
    "        \"\"\"관리한계 계산 (X-bar, R charts)\"\"\"\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data, ddof=1)\n",
    "        \n",
    "        ucl = mean + n_sigma * std  # Upper Control Limit\n",
    "        lcl = mean - n_sigma * std  # Lower Control Limit\n",
    "        \n",
    "        self.control_limits = {\n",
    "            'UCL': ucl,\n",
    "            'CL': mean,\n",
    "            'LCL': lcl,\n",
    "            'sigma': std\n",
    "        }\n",
    "        \n",
    "        return self.control_limits\n",
    "    \n",
    "    def check_control_rules(self, data):\n",
    "        \"\"\"Western Electric 규칙 검사\"\"\"\n",
    "        violations = []\n",
    "        ucl = self.control_limits['UCL']\n",
    "        lcl = self.control_limits['LCL']\n",
    "        cl = self.control_limits['CL']\n",
    "        sigma = self.control_limits['sigma']\n",
    "        \n",
    "        # Rule 1: 1 point beyond 3σ\n",
    "        rule1 = np.where((data > ucl) | (data < lcl))[0]\n",
    "        if len(rule1) > 0:\n",
    "            violations.append({'rule': 1, 'indices': rule1.tolist(),\n",
    "                             'description': 'Point beyond 3σ limits'})\n",
    "        \n",
    "        # Rule 2: 2 out of 3 consecutive points beyond 2σ\n",
    "        for i in range(len(data) - 2):\n",
    "            subset = data[i:i+3]\n",
    "            beyond_2sigma = np.sum((subset > cl + 2*sigma) | \n",
    "                                  (subset < cl - 2*sigma))\n",
    "            if beyond_2sigma >= 2:\n",
    "                violations.append({'rule': 2, 'indices': [i, i+1, i+2],\n",
    "                                 'description': '2 of 3 points beyond 2σ'})\n",
    "        \n",
    "        # Rule 3: 4 out of 5 consecutive points beyond 1σ\n",
    "        for i in range(len(data) - 4):\n",
    "            subset = data[i:i+5]\n",
    "            beyond_1sigma = np.sum((subset > cl + sigma) | \n",
    "                                  (subset < cl - sigma))\n",
    "            if beyond_1sigma >= 4:\n",
    "                violations.append({'rule': 3, 'indices': list(range(i, i+5)),\n",
    "                                 'description': '4 of 5 points beyond 1σ'})\n",
    "        \n",
    "        # Rule 4: 8 consecutive points on one side of centerline\n",
    "        for i in range(len(data) - 7):\n",
    "            subset = data[i:i+8]\n",
    "            if np.all(subset > cl) or np.all(subset < cl):\n",
    "                violations.append({'rule': 4, 'indices': list(range(i, i+8)),\n",
    "                                 'description': '8 points on one side'})\n",
    "        \n",
    "        return violations\n",
    "    \n",
    "    def calculate_process_capability(self, data, usl, lsl):\n",
    "        \"\"\"공정능력지수 계산 (Cp, Cpk)\"\"\"\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data, ddof=1)\n",
    "        \n",
    "        # Cp: 공정능력지수 (규격 폭 / 공정 변동)\n",
    "        cp = (usl - lsl) / (6 * std)\n",
    "        \n",
    "        # Cpk: 치우침을 고려한 공정능력지수\n",
    "        cpu = (usl - mean) / (3 * std)\n",
    "        cpl = (mean - lsl) / (3 * std)\n",
    "        cpk = min(cpu, cpl)\n",
    "        \n",
    "        # Pp, Ppk: 장기 공정능력\n",
    "        pp = cp  # 단기와 동일하게 계산 (실제로는 장기 표준편차 사용)\n",
    "        ppk = cpk\n",
    "        \n",
    "        # 불량률 예측 (ppm)\n",
    "        z_usl = (usl - mean) / std\n",
    "        z_lsl = (lsl - mean) / std\n",
    "        ppm_upper = (1 - stats.norm.cdf(z_usl)) * 1e6\n",
    "        ppm_lower = stats.norm.cdf(z_lsl) * 1e6\n",
    "        ppm_total = ppm_upper + ppm_lower\n",
    "        \n",
    "        self.process_capability = {\n",
    "            'Cp': cp,\n",
    "            'Cpk': cpk,\n",
    "            'Pp': pp,\n",
    "            'Ppk': ppk,\n",
    "            'PPM_total': ppm_total,\n",
    "            'PPM_upper': ppm_upper,\n",
    "            'PPM_lower': ppm_lower\n",
    "        }\n",
    "        \n",
    "        return self.process_capability\n",
    "    \n",
    "    def plot_control_chart(self, data, title='Control Chart'):\n",
    "        \"\"\"관리도 그리기\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "        \n",
    "        # X-bar chart\n",
    "        ax1.plot(data, 'o-', markersize=4, linewidth=1, color='blue')\n",
    "        ax1.axhline(y=self.control_limits['UCL'], color='red', \n",
    "                   linestyle='--', label='UCL')\n",
    "        ax1.axhline(y=self.control_limits['CL'], color='green', \n",
    "                   linestyle='-', label='CL')\n",
    "        ax1.axhline(y=self.control_limits['LCL'], color='red', \n",
    "                   linestyle='--', label='LCL')\n",
    "        \n",
    "        # 2σ lines\n",
    "        ax1.axhline(y=self.control_limits['CL'] + 2*self.control_limits['sigma'], \n",
    "                   color='orange', linestyle=':', alpha=0.5)\n",
    "        ax1.axhline(y=self.control_limits['CL'] - 2*self.control_limits['sigma'], \n",
    "                   color='orange', linestyle=':', alpha=0.5)\n",
    "        \n",
    "        # 1σ lines\n",
    "        ax1.axhline(y=self.control_limits['CL'] + self.control_limits['sigma'], \n",
    "                   color='yellow', linestyle=':', alpha=0.5)\n",
    "        ax1.axhline(y=self.control_limits['CL'] - self.control_limits['sigma'], \n",
    "                   color='yellow', linestyle=':', alpha=0.5)\n",
    "        \n",
    "        ax1.set_ylabel('Measurement')\n",
    "        ax1.set_title(f'{title} - X-bar Chart')\n",
    "        ax1.legend(loc='upper right')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Moving Range chart\n",
    "        mr = np.abs(np.diff(data))\n",
    "        mr_mean = np.mean(mr)\n",
    "        mr_ucl = mr_mean * 3.267  # D4 for n=2\n",
    "        \n",
    "        ax2.plot(mr, 'o-', markersize=4, linewidth=1, color='purple')\n",
    "        ax2.axhline(y=mr_ucl, color='red', linestyle='--', label='UCL')\n",
    "        ax2.axhline(y=mr_mean, color='green', linestyle='-', label='CL')\n",
    "        ax2.axhline(y=0, color='red', linestyle='--', label='LCL')\n",
    "        \n",
    "        ax2.set_xlabel('Sample')\n",
    "        ax2.set_ylabel('Moving Range')\n",
    "        ax2.set_title('Moving Range Chart')\n",
    "        ax2.legend(loc='upper right')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# SPC 시뮬레이션\n",
    "# 생산 데이터 시뮬레이션 (100개 샘플)\n",
    "np.random.seed(42)\n",
    "production_data = np.random.normal(85, 3, 100)\n",
    "\n",
    "# 일부 이상 패턴 주입\n",
    "production_data[30:35] = np.random.normal(92, 2, 5)  # 상한 이탈\n",
    "production_data[60:68] = np.random.normal(87, 1, 8)  # 한쪽 치우침\n",
    "\n",
    "# SPC 분석\n",
    "spc = StatisticalProcessControl()\n",
    "\n",
    "# 관리한계 계산\n",
    "control_limits = spc.calculate_control_limits(production_data[:30])  # 초기 30개로 한계 설정\n",
    "print(\"Control Limits:\")\n",
    "for key, value in control_limits.items():\n",
    "    print(f\"  {key}: {value:.2f}\")\n",
    "\n",
    "# 규칙 위반 검사\n",
    "violations = spc.check_control_rules(production_data)\n",
    "print(f\"\\nFound {len(violations)} rule violations\")\n",
    "for v in violations[:3]:  # 처음 3개만 출력\n",
    "    print(f\"  Rule {v['rule']}: {v['description']} at indices {v['indices'][:5]}...\")\n",
    "\n",
    "# 공정능력 계산 (USL=95, LSL=75)\n",
    "process_cap = spc.calculate_process_capability(production_data, usl=95, lsl=75)\n",
    "print(\"\\nProcess Capability:\")\n",
    "for key, value in process_cap.items():\n",
    "    if 'PPM' in key:\n",
    "        print(f\"  {key}: {value:.1f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "\n",
    "# 관리도 그리기\n",
    "spc.plot_control_chart(production_data, title='Quality Characteristic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. EWMA와 기타 관리도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedControlCharts:\n",
    "    \"\"\"고급 관리도 (EWMA, CUSUM)\"\"\"\n",
    "    \n",
    "    def ewma_chart(self, data, lambda_param=0.2, L=3):\n",
    "        \"\"\"EWMA (Exponentially Weighted Moving Average) 관리도\"\"\"\n",
    "        n = len(data)\n",
    "        ewma = np.zeros(n)\n",
    "        \n",
    "        # 초기값\n",
    "        ewma[0] = data[0]\n",
    "        \n",
    "        # EWMA 계산\n",
    "        for i in range(1, n):\n",
    "            ewma[i] = lambda_param * data[i] + (1 - lambda_param) * ewma[i-1]\n",
    "        \n",
    "        # 관리한계 계산\n",
    "        mean = np.mean(data[:30])  # 초기 데이터로 평균 추정\n",
    "        std = np.std(data[:30], ddof=1)\n",
    "        \n",
    "        # EWMA 관리한계 (시간에 따라 변함)\n",
    "        ucl = np.zeros(n)\n",
    "        lcl = np.zeros(n)\n",
    "        \n",
    "        for i in range(n):\n",
    "            variance_factor = np.sqrt(lambda_param / (2 - lambda_param) * \n",
    "                                     (1 - (1 - lambda_param)**(2*(i+1))))\n",
    "            ucl[i] = mean + L * std * variance_factor\n",
    "            lcl[i] = mean - L * std * variance_factor\n",
    "        \n",
    "        return ewma, ucl, lcl, mean\n",
    "    \n",
    "    def cusum_chart(self, data, target, k=0.5, h=5):\n",
    "        \"\"\"CUSUM (Cumulative Sum) 관리도\"\"\"\n",
    "        n = len(data)\n",
    "        cusum_pos = np.zeros(n)\n",
    "        cusum_neg = np.zeros(n)\n",
    "        \n",
    "        std = np.std(data[:30], ddof=1)\n",
    "        \n",
    "        for i in range(1, n):\n",
    "            cusum_pos[i] = max(0, data[i] - (target + k*std) + cusum_pos[i-1])\n",
    "            cusum_neg[i] = max(0, (target - k*std) - data[i] + cusum_neg[i-1])\n",
    "        \n",
    "        # 결정한계\n",
    "        h_line = h * std\n",
    "        \n",
    "        return cusum_pos, cusum_neg, h_line\n",
    "    \n",
    "    def plot_advanced_charts(self, data, title='Advanced Control Charts'):\n",
    "        \"\"\"고급 관리도 시각화\"\"\"\n",
    "        fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
    "        \n",
    "        # 원본 데이터\n",
    "        axes[0].plot(data, 'o-', markersize=3, linewidth=1, color='blue', alpha=0.6)\n",
    "        axes[0].set_ylabel('Original Data')\n",
    "        axes[0].set_title(f'{title} - Original Data')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # EWMA Chart\n",
    "        ewma, ucl, lcl, mean = self.ewma_chart(data)\n",
    "        axes[1].plot(ewma, 'o-', markersize=3, linewidth=1, color='green', label='EWMA')\n",
    "        axes[1].plot(ucl, 'r--', label='UCL')\n",
    "        axes[1].plot(lcl, 'r--', label='LCL')\n",
    "        axes[1].axhline(y=mean, color='gray', linestyle='-', alpha=0.5, label='Target')\n",
    "        axes[1].set_ylabel('EWMA Value')\n",
    "        axes[1].set_title('EWMA Control Chart (λ=0.2)')\n",
    "        axes[1].legend(loc='upper right')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # CUSUM Chart\n",
    "        target = np.mean(data[:30])\n",
    "        cusum_pos, cusum_neg, h_line = self.cusum_chart(data, target)\n",
    "        axes[2].plot(cusum_pos, 'b-', linewidth=1.5, label='C+ (Upper)')\n",
    "        axes[2].plot(-cusum_neg, 'r-', linewidth=1.5, label='C- (Lower)')\n",
    "        axes[2].axhline(y=h_line, color='red', linestyle='--', alpha=0.5, label='Decision Limit')\n",
    "        axes[2].axhline(y=-h_line, color='red', linestyle='--', alpha=0.5)\n",
    "        axes[2].axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "        axes[2].set_xlabel('Sample')\n",
    "        axes[2].set_ylabel('CUSUM Value')\n",
    "        axes[2].set_title('CUSUM Control Chart')\n",
    "        axes[2].legend(loc='upper right')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# 고급 관리도 적용\n",
    "acc = AdvancedControlCharts()\n",
    "acc.plot_advanced_charts(production_data, title='Quality Monitoring')\n",
    "\n",
    "# EWMA vs Standard Chart 민감도 비교\n",
    "print(\"\\nControl Chart Sensitivity Comparison:\")\n",
    "print(\"- Standard X-bar chart: Detects large shifts quickly\")\n",
    "print(\"- EWMA chart: Better for detecting small sustained shifts\")\n",
    "print(\"- CUSUM chart: Excellent for detecting small shifts, accumulates evidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 과제\n",
    "\n",
    "1. **실험계획 최적화**: 자신의 공정에 맞는 DoE 설계 및 최적 조건 탐색\n",
    "2. **앙상블 모델 개선**: Stacking, Voting 등 고급 앙상블 기법 적용\n",
    "3. **실시간 SPC**: 스트리밍 데이터에서 작동하는 실시간 관리도 구현\n",
    "4. **다변량 관리도**: Hotelling T² 차트 등 다변량 공정 모니터링 구현"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}