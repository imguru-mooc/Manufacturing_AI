{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9RoSIHlFD0w"
      },
      "source": [
        "# ì œì¡° AI ì‹¤ìŠµ ê³¼ì • - Session 2 (2-4ì‹œê°„)\n",
        "## ë¹„ì „ ë¶ˆëŸ‰ê²€ì‚¬ ê³ ë„í™”\n",
        "\n",
        "### í•™ìŠµ ëª©í‘œ\n",
        "- ë°ì´í„° ìˆ˜ì§‘/ë¼ë²¨ í’ˆì§ˆê´€ë¦¬ & ì¡°ëª…/ë Œì¦ˆ ê°€ì´ë“œ ì´í•´\n",
        "- ì „ì´í•™ìŠµ+YOLO/ì„¸ê·¸ë©˜í…Œì´ì…˜ ì ìš© ì „ëµ ìŠµë“\n",
        "- ì„ê³„ê°’ íŠœë‹ê³¼ ì˜¤íƒ/ë¯¸íƒ íŠ¸ë ˆì´ë“œì˜¤í”„ ìµœì í™”\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t540_000FD0x"
      },
      "source": [
        "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "í•œê¸€ ê¹¨ì§ ë°©ì§€\n",
        "\n",
        "Step 1: ì‹¤í–‰"
      ],
      "metadata": {
        "id": "pHZ2c2--FKrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y fonts-nanum*\n",
        "!rm -rf /root/.cache/matplotlib/* # í°íŠ¸ ìºì‹œ ì¬ì„¤ì •\n",
        "print(\"=\" * 50)\n",
        "print(\"âœ… í°íŠ¸ ì„¤ì¹˜ ì™„ë£Œ!\")\n",
        "print(\"âš ï¸ ì´ì œ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:\")\n",
        "print(\"1. ìƒë‹¨ ë©”ë‰´: ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ë‹¤ì‹œ ì‹œì‘\")\n",
        "print(\"2. ì¬ì‹œì‘ í›„ Step 2 ì½”ë“œ ì‹¤í–‰\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "Qu0DOkTnFG63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: ì‹¤í–‰"
      ],
      "metadata": {
        "id": "xdb04MrqF5Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "#\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "font_name = mpl.font_manager.FontProperties(fname=path).get_name()\n",
        "plt.rcParams['font.family'] = font_name\n",
        "\n",
        "# í™•ì¸\n",
        "plt.plot([1,2,3], [1,2,3])\n",
        "plt.title('í•œê¸€ í…ŒìŠ¤íŠ¸ ì„±ê³µ! ğŸ‰')\n",
        "plt.xlabel('í•œê¸€ Xì¶•')\n",
        "plt.ylabel('í•œê¸€ Yì¶•')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nQauR_PIF9FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9YfQMMSFD0y"
      },
      "outputs": [],
      "source": [
        "# YOLOv8 ë° í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install ultralytics -q\n",
        "!pip install opencv-python-headless pillow -q\n",
        "!pip install torch torchvision -q\n",
        "!pip install scikit-image scikit-learn -q\n",
        "!pip install albumentations -q\n",
        "!pip install labelme -q  # ë¼ë²¨ë§ ë„êµ¬\n",
        "!pip install roboflow -q  # ë°ì´í„°ì…‹ ê´€ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ewk7k9yFD0y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# YOLOv8\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Image Processing\n",
        "from skimage import measure, morphology, filters\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import albumentations as A\n",
        "\n",
        "# ì‹œê°í™” ì„¤ì •\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "# GPU í™•ì¸\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"âœ… Device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a431LHD9FD0y"
      },
      "source": [
        "## 2. ì œì¡° ë¶ˆëŸ‰ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜ ë° ìˆ˜ì§‘\n",
        "\n",
        "### 2.1 ë¶ˆëŸ‰ ìœ í˜• ì •ì˜ ë° ìƒ˜í”Œ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d96gC8uFFD0y"
      },
      "outputs": [],
      "source": [
        "class ManufacturingDefectSimulator:\n",
        "    def __init__(self):\n",
        "        self.defect_types = {\n",
        "            'scratch': {'color': (255, 0, 0), 'severity': ['minor', 'major', 'critical']},\n",
        "            'dent': {'color': (0, 255, 0), 'severity': ['shallow', 'deep']},\n",
        "            'contamination': {'color': (0, 0, 255), 'severity': ['light', 'heavy']},\n",
        "            'crack': {'color': (255, 255, 0), 'severity': ['hairline', 'visible', 'severe']},\n",
        "            'discoloration': {'color': (255, 0, 255), 'severity': ['slight', 'moderate', 'severe']}\n",
        "        }\n",
        "\n",
        "    def generate_synthetic_image(self, width=640, height=480, defect_type=None):\n",
        "        \"\"\"í•©ì„± ë¶ˆëŸ‰ ì´ë¯¸ì§€ ìƒì„±\"\"\"\n",
        "        # ê¸°ë³¸ ë°°ê²½ ìƒì„± (ì œí’ˆ í‘œë©´ ì‹œë®¬ë ˆì´ì…˜)\n",
        "        image = np.ones((height, width, 3), dtype=np.uint8) * 200\n",
        "\n",
        "        # í…ìŠ¤ì²˜ ì¶”ê°€\n",
        "        noise = np.random.normal(0, 10, (height, width, 3))\n",
        "        image = np.clip(image + noise, 0, 255).astype(np.uint8)\n",
        "\n",
        "        annotations = []\n",
        "\n",
        "        if defect_type:\n",
        "            # ë¶ˆëŸ‰ ì¶”ê°€\n",
        "            if defect_type == 'scratch':\n",
        "                # ìŠ¤í¬ë˜ì¹˜ ìƒì„±\n",
        "                x1, y1 = np.random.randint(50, width-50), np.random.randint(50, height-50)\n",
        "                x2, y2 = x1 + np.random.randint(50, 200), y1 + np.random.randint(-30, 30)\n",
        "                cv2.line(image, (x1, y1), (x2, y2), self.defect_types[defect_type]['color'], 2)\n",
        "\n",
        "                bbox = [min(x1, x2), min(y1, y2), abs(x2-x1), abs(y2-y1)+4]\n",
        "                annotations.append({\n",
        "                    'type': defect_type,\n",
        "                    'bbox': bbox,\n",
        "                    'severity': np.random.choice(self.defect_types[defect_type]['severity'])\n",
        "                })\n",
        "\n",
        "            elif defect_type == 'dent':\n",
        "                # ë´íŠ¸ ìƒì„±\n",
        "                center = (np.random.randint(50, width-50), np.random.randint(50, height-50))\n",
        "                radius = np.random.randint(20, 50)\n",
        "                cv2.circle(image, center, radius, self.defect_types[defect_type]['color'], -1)\n",
        "\n",
        "                bbox = [center[0]-radius, center[1]-radius, radius*2, radius*2]\n",
        "                annotations.append({\n",
        "                    'type': defect_type,\n",
        "                    'bbox': bbox,\n",
        "                    'severity': np.random.choice(self.defect_types[defect_type]['severity'])\n",
        "                })\n",
        "\n",
        "            elif defect_type == 'contamination':\n",
        "                # ì˜¤ì—¼ ìƒì„±\n",
        "                x, y = np.random.randint(50, width-100), np.random.randint(50, height-100)\n",
        "                w, h = np.random.randint(30, 100), np.random.randint(30, 100)\n",
        "\n",
        "                contamination = np.random.randint(100, 150, (h, w, 3))\n",
        "                image[y:y+h, x:x+w] = contamination\n",
        "\n",
        "                bbox = [x, y, w, h]\n",
        "                annotations.append({\n",
        "                    'type': defect_type,\n",
        "                    'bbox': bbox,\n",
        "                    'severity': np.random.choice(self.defect_types[defect_type]['severity'])\n",
        "                })\n",
        "\n",
        "        return image, annotations\n",
        "\n",
        "    def generate_dataset(self, n_images=100, defect_ratio=0.3):\n",
        "        \"\"\"ë°ì´í„°ì…‹ ìƒì„±\"\"\"\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(n_images):\n",
        "            if np.random.random() < defect_ratio:\n",
        "                # ë¶ˆëŸ‰ ì´ë¯¸ì§€\n",
        "                defect_type = np.random.choice(list(self.defect_types.keys()))\n",
        "                img, annot = self.generate_synthetic_image(defect_type=defect_type)\n",
        "                images.append(img)\n",
        "                labels.append(annot)\n",
        "            else:\n",
        "                # ì •ìƒ ì´ë¯¸ì§€\n",
        "                img, _ = self.generate_synthetic_image(defect_type=None)\n",
        "                images.append(img)\n",
        "                labels.append([])\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "# ë¶ˆëŸ‰ ë°ì´í„° ìƒì„±\n",
        "simulator = ManufacturingDefectSimulator()\n",
        "sample_images, sample_labels = simulator.generate_dataset(n_images=50, defect_ratio=0.5)\n",
        "\n",
        "# ìƒ˜í”Œ ì‹œê°í™”\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Synthetic Manufacturing Defect Samples', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, ax in enumerate(axes.flat):\n",
        "    if idx < len(sample_images):\n",
        "        img = sample_images[idx]\n",
        "        label = sample_labels[idx]\n",
        "\n",
        "        ax.imshow(img)\n",
        "\n",
        "        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
        "        if label:\n",
        "            for annot in label:\n",
        "                x, y, w, h = annot['bbox']\n",
        "                rect = plt.Rectangle((x, y), w, h, linewidth=2,\n",
        "                                    edgecolor='red', facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "                ax.text(x, y-5, f\"{annot['type']} ({annot['severity']})\",\n",
        "                       color='red', fontsize=8, weight='bold')\n",
        "\n",
        "        status = \"Defective\" if label else \"Normal\"\n",
        "        ax.set_title(f\"Sample {idx+1}: {status}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"âœ… ìƒì„±ëœ ë°ì´í„°ì…‹: {len(sample_images)} ì´ë¯¸ì§€\")\n",
        "print(f\"   - ë¶ˆëŸ‰: {sum(1 for l in sample_labels if l)} ê°œ\")\n",
        "print(f\"   - ì •ìƒ: {sum(1 for l in sample_labels if not l)} ê°œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NShxqpxfFD0z"
      },
      "source": [
        "### 2.2 ì¡°ëª… ë° ì¹´ë©”ë¼ ì„¤ì • ê°€ì´ë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHFYypA0FD0z"
      },
      "outputs": [],
      "source": [
        "class VisionSystemGuide:\n",
        "    def __init__(self):\n",
        "        self.lighting_types = {\n",
        "            'Front Light': {\n",
        "                'use_case': 'ì¼ë°˜ì ì¸ í‘œë©´ ê²€ì‚¬',\n",
        "                'advantages': 'ê· ì¼í•œ ì¡°ëª…, ìƒ‰ìƒ ì¬í˜„ì„± ì¢‹ìŒ',\n",
        "                'disadvantages': 'ê·¸ë¦¼ì ë°œìƒ ê°€ëŠ¥'\n",
        "            },\n",
        "            'Back Light': {\n",
        "                'use_case': 'ì™¸í˜• ê²€ì‚¬, êµ¬ë©/í¬ë™ ê²€ì¶œ',\n",
        "                'advantages': 'ë†’ì€ ëŒ€ë¹„, ì™¸í˜• ëª…í™•',\n",
        "                'disadvantages': 'í‘œë©´ ì„¸ë¶€ì‚¬í•­ ì†ì‹¤'\n",
        "            },\n",
        "            'Coaxial Light': {\n",
        "                'use_case': 'ë°˜ì‚¬ í‘œë©´ ê²€ì‚¬',\n",
        "                'advantages': 'ê· ì¼í•œ ì¡°ëª…, ë°˜ì‚¬ ìµœì†Œí™”',\n",
        "                'disadvantages': 'ë¹„ìš© ë†’ìŒ'\n",
        "            },\n",
        "            'Ring Light': {\n",
        "                'use_case': 'ì‘ì€ ë¶€í’ˆ ê²€ì‚¬',\n",
        "                'advantages': 'ê·¸ë¦¼ì ì—†ìŒ, ê· ì¼í•œ ì¡°ëª…',\n",
        "                'disadvantages': 'ì œí•œëœ ì‘ì—… ê±°ë¦¬'\n",
        "            },\n",
        "            'Dome Light': {\n",
        "                'use_case': 'ê³¡ë©´/ë°˜ì‚¬ í‘œë©´',\n",
        "                'advantages': 'ë§¤ìš° ê· ì¼í•œ ì¡°ëª…',\n",
        "                'disadvantages': 'í¬ê¸° ì œí•œ, ë¹„ìš©'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.camera_specs = {\n",
        "            'resolution': {'min': '1920x1080', 'recommended': '2448x2048', 'high': '4096x3072'},\n",
        "            'fps': {'inspection': 30, 'high_speed': 120, 'ultra_high': 500},\n",
        "            'sensor_type': ['CCD', 'CMOS'],\n",
        "            'pixel_size': {'standard': '3.45Î¼m', 'high_sensitivity': '5.5Î¼m'}\n",
        "        }\n",
        "\n",
        "    def simulate_lighting_effect(self, image, lighting_type):\n",
        "        \"\"\"ì¡°ëª… íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜\"\"\"\n",
        "        if lighting_type == 'Front Light':\n",
        "            # ì „ë©´ ì¡°ëª… íš¨ê³¼\n",
        "            result = cv2.addWeighted(image, 1.2, np.ones_like(image)*255, 0.1, 0)\n",
        "\n",
        "        elif lighting_type == 'Back Light':\n",
        "            # í›„ë©´ ì¡°ëª… íš¨ê³¼ (ì‹¤ë£¨ì—£)\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "            _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
        "            result = cv2.cvtColor(binary, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "        elif lighting_type == 'Coaxial Light':\n",
        "            # ë™ì¶• ì¡°ëª… íš¨ê³¼\n",
        "            result = cv2.bilateralFilter(image, 9, 75, 75)\n",
        "\n",
        "        elif lighting_type == 'Ring Light':\n",
        "            # ë§ ì¡°ëª… íš¨ê³¼\n",
        "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "            result = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel)\n",
        "            result = cv2.addWeighted(image, 0.7, result, 0.3, 0)\n",
        "\n",
        "        else:  # Dome Light\n",
        "            # ë” ì¡°ëª… íš¨ê³¼\n",
        "            result = cv2.GaussianBlur(image, (3, 3), 0)\n",
        "            result = cv2.addWeighted(result, 1.1, np.ones_like(image)*255, 0.05, 0)\n",
        "\n",
        "        return np.clip(result, 0, 255).astype(np.uint8)\n",
        "\n",
        "    def recommend_setup(self, defect_type):\n",
        "        \"\"\"ë¶ˆëŸ‰ ìœ í˜•ë³„ ìµœì  ì„¸íŒ… ì¶”ì²œ\"\"\"\n",
        "        recommendations = {\n",
        "            'scratch': {\n",
        "                'lighting': 'Coaxial Light or Low-angle Light',\n",
        "                'camera': 'ê³ í•´ìƒë„ (>5MP), ë§¤í¬ë¡œ ë Œì¦ˆ',\n",
        "                'processing': 'Edge detection, Gradient analysis'\n",
        "            },\n",
        "            'dent': {\n",
        "                'lighting': '3D structured light or Shadow technique',\n",
        "                'camera': 'Stereo vision or 3D camera',\n",
        "                'processing': 'Depth mapping, Surface reconstruction'\n",
        "            },\n",
        "            'contamination': {\n",
        "                'lighting': 'UV light or Polarized light',\n",
        "                'camera': 'Color camera with good SNR',\n",
        "                'processing': 'Color segmentation, Texture analysis'\n",
        "            },\n",
        "            'crack': {\n",
        "                'lighting': 'Back light or Transmitted light',\n",
        "                'camera': 'High resolution, Telecentric lens',\n",
        "                'processing': 'Morphological operations, Line detection'\n",
        "            },\n",
        "            'discoloration': {\n",
        "                'lighting': 'Diffuse dome light',\n",
        "                'camera': 'Calibrated color camera',\n",
        "                'processing': 'Color space analysis, Statistical methods'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return recommendations.get(defect_type, {})\n",
        "\n",
        "# ì¡°ëª… íš¨ê³¼ ì‹œë®¬ë ˆì´ì…˜\n",
        "vision_guide = VisionSystemGuide()\n",
        "\n",
        "# ì›ë³¸ ì´ë¯¸ì§€ì— ë‹¤ì–‘í•œ ì¡°ëª… íš¨ê³¼ ì ìš©\n",
        "test_image = sample_images[0]\n",
        "lighting_effects = ['Front Light', 'Back Light', 'Coaxial Light', 'Ring Light', 'Dome Light']\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Different Lighting Effects on Defect Detection', fontsize=16, fontweight='bold')\n",
        "\n",
        "axes[0, 0].imshow(test_image)\n",
        "axes[0, 0].set_title('Original Image')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "for idx, (ax, light_type) in enumerate(zip(axes.flat[1:], lighting_effects)):\n",
        "    processed = vision_guide.simulate_lighting_effect(test_image, light_type)\n",
        "    ax.imshow(processed)\n",
        "    ax.set_title(f'{light_type}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ë¶ˆëŸ‰ ìœ í˜•ë³„ ì¶”ì²œ ì„¤ì • ì¶œë ¥\n",
        "print(\"\\nğŸ“¸ ë¶ˆëŸ‰ ìœ í˜•ë³„ ìµœì  ë¹„ì „ ì‹œìŠ¤í…œ ì„¤ì •:\\n\")\n",
        "for defect in ['scratch', 'dent', 'contamination']:\n",
        "    rec = vision_guide.recommend_setup(defect)\n",
        "    print(f\"ğŸ” {defect.upper()}:\")\n",
        "    for key, value in rec.items():\n",
        "        print(f\"   - {key}: {value}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onKdrJ6nFD0z"
      },
      "source": [
        "### 2.3 ë°ì´í„° ë¼ë²¨ë§ í’ˆì§ˆ ê´€ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C77IgpIWFD0z"
      },
      "outputs": [],
      "source": [
        "class LabelQualityManager:\n",
        "    def __init__(self):\n",
        "        self.labeling_guidelines = {\n",
        "            'consistency': 'Same defect type should be labeled identically across images',\n",
        "            'completeness': 'All visible defects must be labeled',\n",
        "            'accuracy': 'Bounding boxes should tightly fit defects',\n",
        "            'granularity': 'Use appropriate class hierarchy (defect â†’ type â†’ severity)'\n",
        "        }\n",
        "\n",
        "        self.quality_metrics = {}\n",
        "\n",
        "    def check_label_quality(self, annotations):\n",
        "        \"\"\"ë¼ë²¨ í’ˆì§ˆ ê²€ì‚¬\"\"\"\n",
        "        issues = []\n",
        "\n",
        "        for idx, annot in enumerate(annotations):\n",
        "            if not annot:\n",
        "                continue\n",
        "\n",
        "            for item in annot:\n",
        "                bbox = item.get('bbox', [])\n",
        "\n",
        "                # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ê²€ì‚¬\n",
        "                if len(bbox) == 4:\n",
        "                    x, y, w, h = bbox\n",
        "\n",
        "                    # ë„ˆë¬´ ì‘ì€ ë°•ìŠ¤\n",
        "                    if w < 10 or h < 10:\n",
        "                        issues.append({\n",
        "                            'image_idx': idx,\n",
        "                            'issue': 'Bounding box too small',\n",
        "                            'bbox': bbox\n",
        "                        })\n",
        "\n",
        "                    # ë¹„ì •ìƒì  ë¹„ìœ¨\n",
        "                    aspect_ratio = w / h if h > 0 else 0\n",
        "                    if aspect_ratio > 10 or aspect_ratio < 0.1:\n",
        "                        issues.append({\n",
        "                            'image_idx': idx,\n",
        "                            'issue': 'Abnormal aspect ratio',\n",
        "                            'bbox': bbox,\n",
        "                            'ratio': aspect_ratio\n",
        "                        })\n",
        "\n",
        "                # ë¼ë²¨ ëˆ„ë½ ê²€ì‚¬\n",
        "                if not item.get('type'):\n",
        "                    issues.append({\n",
        "                        'image_idx': idx,\n",
        "                        'issue': 'Missing defect type'\n",
        "                    })\n",
        "\n",
        "        return issues\n",
        "\n",
        "    def calculate_inter_annotator_agreement(self, annotations1, annotations2):\n",
        "        \"\"\"ë¼ë²¨ëŸ¬ ê°„ ì¼ì¹˜ë„ ê³„ì‚° (IoU ê¸°ë°˜)\"\"\"\n",
        "        agreements = []\n",
        "\n",
        "        for ann1, ann2 in zip(annotations1, annotations2):\n",
        "            if not ann1 and not ann2:\n",
        "                agreements.append(1.0)  # ë‘˜ ë‹¤ ì •ìƒìœ¼ë¡œ íŒì •\n",
        "            elif not ann1 or not ann2:\n",
        "                agreements.append(0.0)  # ë¶ˆì¼ì¹˜\n",
        "            else:\n",
        "                # IoU ê³„ì‚°\n",
        "                iou_scores = []\n",
        "                for box1 in ann1:\n",
        "                    for box2 in ann2:\n",
        "                        iou = self.calculate_iou(box1['bbox'], box2['bbox'])\n",
        "                        if box1['type'] == box2['type']:\n",
        "                            iou_scores.append(iou)\n",
        "                        else:\n",
        "                            iou_scores.append(0)\n",
        "\n",
        "                if iou_scores:\n",
        "                    agreements.append(np.mean(iou_scores))\n",
        "                else:\n",
        "                    agreements.append(0.0)\n",
        "\n",
        "        return np.mean(agreements)\n",
        "\n",
        "    def calculate_iou(self, box1, box2):\n",
        "        \"\"\"IoU (Intersection over Union) ê³„ì‚°\"\"\"\n",
        "        x1, y1, w1, h1 = box1\n",
        "        x2, y2, w2, h2 = box2\n",
        "\n",
        "        # êµì§‘í•© ì˜ì—­\n",
        "        xi1 = max(x1, x2)\n",
        "        yi1 = max(y1, y2)\n",
        "        xi2 = min(x1 + w1, x2 + w2)\n",
        "        yi2 = min(y1 + h1, y2 + h2)\n",
        "\n",
        "        if xi2 < xi1 or yi2 < yi1:\n",
        "            return 0.0\n",
        "\n",
        "        intersection = (xi2 - xi1) * (yi2 - yi1)\n",
        "        union = w1 * h1 + w2 * h2 - intersection\n",
        "\n",
        "        return intersection / union if union > 0 else 0\n",
        "\n",
        "    def generate_labeling_report(self, annotations):\n",
        "        \"\"\"ë¼ë²¨ë§ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±\"\"\"\n",
        "        total_images = len(annotations)\n",
        "        labeled_images = sum(1 for ann in annotations if ann)\n",
        "        total_defects = sum(len(ann) for ann in annotations if ann)\n",
        "\n",
        "        defect_distribution = {}\n",
        "        for ann in annotations:\n",
        "            if ann:\n",
        "                for item in ann:\n",
        "                    defect_type = item.get('type', 'unknown')\n",
        "                    defect_distribution[defect_type] = defect_distribution.get(defect_type, 0) + 1\n",
        "\n",
        "        report = {\n",
        "            'total_images': total_images,\n",
        "            'labeled_images': labeled_images,\n",
        "            'labeling_rate': labeled_images / total_images * 100,\n",
        "            'total_defects': total_defects,\n",
        "            'avg_defects_per_image': total_defects / labeled_images if labeled_images > 0 else 0,\n",
        "            'defect_distribution': defect_distribution\n",
        "        }\n",
        "\n",
        "        return report\n",
        "\n",
        "# ë¼ë²¨ í’ˆì§ˆ ê²€ì‚¬\n",
        "label_manager = LabelQualityManager()\n",
        "\n",
        "# í’ˆì§ˆ ì´ìŠˆ ê²€ì‚¬\n",
        "quality_issues = label_manager.check_label_quality(sample_labels)\n",
        "print(\"ğŸ” ë¼ë²¨ í’ˆì§ˆ ê²€ì‚¬ ê²°ê³¼:\")\n",
        "print(f\"   ë°œê²¬ëœ ì´ìŠˆ: {len(quality_issues)} ê°œ\\n\")\n",
        "\n",
        "if quality_issues[:3]:\n",
        "    print(\"   ìƒ˜í”Œ ì´ìŠˆ:\")\n",
        "    for issue in quality_issues[:3]:\n",
        "        print(f\"   - Image {issue['image_idx']}: {issue['issue']}\")\n",
        "\n",
        "# ë¼ë²¨ë§ ë¦¬í¬íŠ¸\n",
        "report = label_manager.generate_labeling_report(sample_labels)\n",
        "print(\"\\nğŸ“Š ë¼ë²¨ë§ í†µê³„ ë¦¬í¬íŠ¸:\")\n",
        "for key, value in report.items():\n",
        "    if key != 'defect_distribution':\n",
        "        print(f\"   {key}: {value:.2f}\" if isinstance(value, float) else f\"   {key}: {value}\")\n",
        "\n",
        "print(\"\\n   ë¶ˆëŸ‰ ìœ í˜• ë¶„í¬:\")\n",
        "for defect_type, count in report['defect_distribution'].items():\n",
        "    print(f\"     - {defect_type}: {count} ê°œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1OjdDKdFD0z"
      },
      "source": [
        "## 3. YOLO ëª¨ë¸ í•™ìŠµ ë° ì „ì´í•™ìŠµ\n",
        "\n",
        "### 3.1 YOLO ëª¨ë¸ ì¤€ë¹„ ë° ë°ì´í„° í¬ë§· ë³€í™˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ceuwebj2FD00"
      },
      "outputs": [],
      "source": [
        "class YOLODataPreparation:\n",
        "    def __init__(self, images, labels):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.class_names = ['scratch', 'dent', 'contamination', 'crack', 'discoloration']\n",
        "        self.class_to_id = {name: idx for idx, name in enumerate(self.class_names)}\n",
        "\n",
        "    def convert_to_yolo_format(self, bbox, img_width, img_height, class_name):\n",
        "        \"\"\"ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
        "        x, y, w, h = bbox\n",
        "\n",
        "        # ì¤‘ì‹¬ì  ì¢Œí‘œì™€ í¬ê¸°ë¥¼ ì •ê·œí™”\n",
        "        center_x = (x + w/2) / img_width\n",
        "        center_y = (y + h/2) / img_height\n",
        "        norm_w = w / img_width\n",
        "        norm_h = h / img_height\n",
        "\n",
        "        class_id = self.class_to_id.get(class_name, 0)\n",
        "\n",
        "        return f\"{class_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\"\n",
        "\n",
        "    def prepare_dataset(self, split_ratio=0.8):\n",
        "        \"\"\"í•™ìŠµ/ê²€ì¦ ë°ì´í„°ì…‹ ì¤€ë¹„\"\"\"\n",
        "        n_samples = len(self.images)\n",
        "        n_train = int(n_samples * split_ratio)\n",
        "\n",
        "        # ë°ì´í„° ì…”í”Œ\n",
        "        indices = np.random.permutation(n_samples)\n",
        "\n",
        "        train_indices = indices[:n_train]\n",
        "        val_indices = indices[n_train:]\n",
        "\n",
        "        # ë””ë ‰í† ë¦¬ ìƒì„±\n",
        "        os.makedirs('dataset/train/images', exist_ok=True)\n",
        "        os.makedirs('dataset/train/labels', exist_ok=True)\n",
        "        os.makedirs('dataset/val/images', exist_ok=True)\n",
        "        os.makedirs('dataset/val/labels', exist_ok=True)\n",
        "\n",
        "        # í•™ìŠµ ë°ì´í„° ì €ì¥\n",
        "        for idx in train_indices:\n",
        "            img = self.images[idx]\n",
        "            label = self.labels[idx]\n",
        "\n",
        "            # ì´ë¯¸ì§€ ì €ì¥\n",
        "            img_path = f'dataset/train/images/img_{idx:04d}.jpg'\n",
        "            cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # ë¼ë²¨ ì €ì¥ (YOLO í¬ë§·)\n",
        "            label_path = f'dataset/train/labels/img_{idx:04d}.txt'\n",
        "            with open(label_path, 'w') as f:\n",
        "                if label:\n",
        "                    h, w = img.shape[:2]\n",
        "                    for annot in label:\n",
        "                        yolo_line = self.convert_to_yolo_format(\n",
        "                            annot['bbox'], w, h, annot['type']\n",
        "                        )\n",
        "                        f.write(yolo_line + '\\n')\n",
        "\n",
        "        # ê²€ì¦ ë°ì´í„° ì €ì¥\n",
        "        for idx in val_indices:\n",
        "            img = self.images[idx]\n",
        "            label = self.labels[idx]\n",
        "\n",
        "            # ì´ë¯¸ì§€ ì €ì¥\n",
        "            img_path = f'dataset/val/images/img_{idx:04d}.jpg'\n",
        "            cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # ë¼ë²¨ ì €ì¥\n",
        "            label_path = f'dataset/val/labels/img_{idx:04d}.txt'\n",
        "            with open(label_path, 'w') as f:\n",
        "                if label:\n",
        "                    h, w = img.shape[:2]\n",
        "                    for annot in label:\n",
        "                        yolo_line = self.convert_to_yolo_format(\n",
        "                            annot['bbox'], w, h, annot['type']\n",
        "                        )\n",
        "                        f.write(yolo_line + '\\n')\n",
        "\n",
        "        # YAML ì„¤ì • íŒŒì¼ ìƒì„±\n",
        "        yaml_content = f\"\"\"# Manufacturing Defect Detection Dataset\n",
        "path: dataset\n",
        "train: train/images\n",
        "val: val/images\n",
        "\n",
        "# Classes\n",
        "nc: {len(self.class_names)}\n",
        "names: {self.class_names}\n",
        "\"\"\"\n",
        "\n",
        "        with open('dataset/defect_data.yaml', 'w') as f:\n",
        "            f.write(yaml_content)\n",
        "\n",
        "        print(f\"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ\")\n",
        "        print(f\"   - Training: {len(train_indices)} images\")\n",
        "        print(f\"   - Validation: {len(val_indices)} images\")\n",
        "\n",
        "        return train_indices, val_indices\n",
        "\n",
        "# YOLO ë°ì´í„°ì…‹ ì¤€ë¹„\n",
        "yolo_prep = YOLODataPreparation(sample_images, sample_labels)\n",
        "train_idx, val_idx = yolo_prep.prepare_dataset(split_ratio=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1hw5V6wFD00"
      },
      "source": [
        "### 3.2 YOLO ëª¨ë¸ í•™ìŠµ ë° ì „ì´í•™ìŠµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQHdco5qFD00"
      },
      "outputs": [],
      "source": [
        "# YOLOv8 ëª¨ë¸ ì´ˆê¸°í™” ë° ì „ì´í•™ìŠµ\n",
        "class YOLODefectDetector:\n",
        "    def __init__(self, model_size='n'):\n",
        "        \"\"\"\n",
        "        model_size: 'n'(nano), 's'(small), 'm'(medium), 'l'(large), 'x'(extra large)\n",
        "        \"\"\"\n",
        "        self.model_size = model_size\n",
        "        self.model = None\n",
        "        self.results = None\n",
        "\n",
        "    def initialize_pretrained_model(self):\n",
        "        \"\"\"ì‚¬ì „ í•™ìŠµëœ YOLO ëª¨ë¸ ë¡œë“œ\"\"\"\n",
        "        model_name = f'yolov8{self.model_size}.pt'\n",
        "        self.model = YOLO(model_name)\n",
        "        print(f\"âœ… Loaded pretrained model: {model_name}\")\n",
        "\n",
        "    def train_model(self, data_yaml, epochs=10, imgsz=640, batch=8):\n",
        "        \"\"\"ëª¨ë¸ í•™ìŠµ\"\"\"\n",
        "        if self.model is None:\n",
        "            self.initialize_pretrained_model()\n",
        "\n",
        "        # í•™ìŠµ íŒŒë¼ë¯¸í„°\n",
        "        self.results = self.model.train(\n",
        "            data=data_yaml,\n",
        "            epochs=epochs,\n",
        "            imgsz=imgsz,\n",
        "            batch=batch,\n",
        "            patience=5,\n",
        "            save=True,\n",
        "            device=device.type,\n",
        "            verbose=True,\n",
        "            # ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "            lr0=0.01,  # ì´ˆê¸° í•™ìŠµë¥ \n",
        "            lrf=0.01,  # ìµœì¢… í•™ìŠµë¥  (lr0 * lrf)\n",
        "            momentum=0.937,\n",
        "            weight_decay=0.0005,\n",
        "            warmup_epochs=3,\n",
        "            warmup_momentum=0.8,\n",
        "            box=7.5,  # box loss gain\n",
        "            cls=0.5,  # cls loss gain\n",
        "            degrees=0.0,  # íšŒì „ ì¦ê°•\n",
        "            translate=0.1,  # ì´ë™ ì¦ê°•\n",
        "            scale=0.5,  # ìŠ¤ì¼€ì¼ ì¦ê°•\n",
        "            flipud=0.0,  # ìƒí•˜ ë°˜ì „\n",
        "            fliplr=0.5,  # ì¢Œìš° ë°˜ì „\n",
        "            mosaic=1.0,  # ëª¨ìì´í¬ ì¦ê°•\n",
        "            mixup=0.0  # MixUp ì¦ê°•\n",
        "        )\n",
        "\n",
        "        print(\"\\nâœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
        "        return self.results\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
        "        if self.model is None:\n",
        "            print(\"âŒ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        # ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€\n",
        "        metrics = self.model.val()\n",
        "\n",
        "        print(\"\\nğŸ“Š ëª¨ë¸ í‰ê°€ ê²°ê³¼:\")\n",
        "        print(f\"   - mAP50: {metrics.box.map50:.4f}\")\n",
        "        print(f\"   - mAP50-95: {metrics.box.map:.4f}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def predict(self, image, conf_threshold=0.25):\n",
        "        \"\"\"ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡\"\"\"\n",
        "        if self.model is None:\n",
        "            print(\"âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "            return None\n",
        "\n",
        "        results = self.model(image, conf=conf_threshold)\n",
        "        return results[0]\n",
        "\n",
        "    def visualize_predictions(self, image, predictions):\n",
        "        \"\"\"ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
        "        img_copy = image.copy()\n",
        "\n",
        "        if predictions.boxes is not None:\n",
        "            boxes = predictions.boxes.xyxy.cpu().numpy()\n",
        "            confidences = predictions.boxes.conf.cpu().numpy()\n",
        "            classes = predictions.boxes.cls.cpu().numpy()\n",
        "\n",
        "            for box, conf, cls in zip(boxes, confidences, classes):\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                class_name = yolo_prep.class_names[int(cls)]\n",
        "\n",
        "                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n",
        "                cv2.rectangle(img_copy, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "                # ë¼ë²¨ ì¶”ê°€\n",
        "                label = f\"{class_name}: {conf:.2f}\"\n",
        "                cv2.putText(img_copy, label, (x1, y1-10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        return img_copy\n",
        "\n",
        "# YOLO ëª¨ë¸ í•™ìŠµ (ì‹œë®¬ë ˆì´ì…˜ - ì‹¤ì œë¡œëŠ” ë” ë§ì€ ì—í­ì´ í•„ìš”)\n",
        "detector = YOLODefectDetector(model_size='n')  # nano ëª¨ë¸ ì‚¬ìš© (ë¹ ë¥¸ í•™ìŠµ)\n",
        "detector.initialize_pretrained_model()\n",
        "\n",
        "# ì°¸ê³ : ì‹¤ì œ í•™ìŠµì€ ë§ì€ ì‹œê°„ì´ ê±¸ë¦¬ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ë§Œ ìˆ˜í–‰\n",
        "print(\"\\nğŸ“ í•™ìŠµ ì„¤ì • ì˜ˆì‹œ:\")\n",
        "print(\"detector.train_model('dataset/defect_data.yaml', epochs=50, batch=16)\")\n",
        "print(\"\\nğŸ’¡ ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ë‹¤ìŒì„ ê¶Œì¥:\")\n",
        "print(\"   - epochs: 100-300\")\n",
        "print(\"   - batch size: GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì • (16-64)\")\n",
        "print(\"   - image size: 640x640 ë˜ëŠ” 1280x1280\")\n",
        "print(\"   - model size: 's' ë˜ëŠ” 'm' (ì •í™•ë„ì™€ ì†ë„ì˜ ê· í˜•)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4y0icgjFD00"
      },
      "source": [
        "## 4. ì„¸ê·¸ë©˜í…Œì´ì…˜ ë° ê³ ê¸‰ ê²€ì‚¬ ê¸°ë²•\n",
        "\n",
        "### 4.1 Instance Segmentation for Precise Defect Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01F6mLE5FD00"
      },
      "outputs": [],
      "source": [
        "class DefectSegmentation:\n",
        "    def __init__(self):\n",
        "        self.segmentation_methods = {\n",
        "            'threshold': 'Simple threshold-based segmentation',\n",
        "            'watershed': 'Watershed algorithm for touching objects',\n",
        "            'grabcut': 'GrabCut for foreground extraction',\n",
        "            'deep_learning': 'U-Net, Mask R-CNN for precise segmentation'\n",
        "        }\n",
        "\n",
        "    def threshold_segmentation(self, image, lower_thresh=100, upper_thresh=200):\n",
        "        \"\"\"ì„ê³„ê°’ ê¸°ë°˜ ì„¸ê·¸ë©˜í…Œì´ì…˜\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        _, binary = cv2.threshold(gray, lower_thresh, upper_thresh, cv2.THRESH_BINARY)\n",
        "\n",
        "        # ë…¸ì´ì¦ˆ ì œê±°\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
        "        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "        return binary\n",
        "\n",
        "    def watershed_segmentation(self, image):\n",
        "        \"\"\"Watershed ì•Œê³ ë¦¬ì¦˜\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # ë…¸ì´ì¦ˆ ì œê±°\n",
        "        denoised = cv2.medianBlur(gray, 5)\n",
        "\n",
        "        # Threshold\n",
        "        _, thresh = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "        # í™•ì‹¤í•œ ë°°ê²½ ì˜ì—­ ì°¾ê¸°\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        sure_bg = cv2.dilate(thresh, kernel, iterations=3)\n",
        "\n",
        "        # í™•ì‹¤í•œ ì „ê²½ ì˜ì—­ ì°¾ê¸°\n",
        "        dist_transform = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)\n",
        "        _, sure_fg = cv2.threshold(dist_transform, 0.3*dist_transform.max(), 255, 0)\n",
        "        sure_fg = np.uint8(sure_fg)\n",
        "\n",
        "        # ë¶ˆí™•ì‹¤í•œ ì˜ì—­ ì°¾ê¸°\n",
        "        unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "        # ë§ˆì»¤ ìƒì„±\n",
        "        _, markers = cv2.connectedComponents(sure_fg)\n",
        "        markers = markers + 1\n",
        "        markers[unknown == 255] = 0\n",
        "\n",
        "        # Watershed ì ìš©\n",
        "        markers = cv2.watershed(image, markers)\n",
        "\n",
        "        # ê²½ê³„ì„  í‘œì‹œ\n",
        "        result = image.copy()\n",
        "        result[markers == -1] = [255, 0, 0]\n",
        "\n",
        "        return markers, result\n",
        "\n",
        "    def extract_defect_features(self, image, mask):\n",
        "        \"\"\"ë¶ˆëŸ‰ ì˜ì—­ì˜ íŠ¹ì§• ì¶”ì¶œ\"\"\"\n",
        "        # ì—°ê²°ëœ êµ¬ì„±ìš”ì†Œ ì°¾ê¸°\n",
        "        labeled = measure.label(mask)\n",
        "        regions = measure.regionprops(labeled, intensity_image=cv2.cvtColor(image, cv2.COLOR_RGB2GRAY))\n",
        "\n",
        "        features = []\n",
        "        for region in regions:\n",
        "            feature = {\n",
        "                'area': region.area,\n",
        "                'perimeter': region.perimeter,\n",
        "                'centroid': region.centroid,\n",
        "                'eccentricity': region.eccentricity,\n",
        "                'solidity': region.solidity,\n",
        "                'mean_intensity': region.mean_intensity,\n",
        "                'bbox': region.bbox,\n",
        "                'major_axis_length': region.major_axis_length,\n",
        "                'minor_axis_length': region.minor_axis_length\n",
        "            }\n",
        "\n",
        "            # í˜•íƒœ ë¶„ë¥˜\n",
        "            if feature['eccentricity'] > 0.9:\n",
        "                feature['shape_type'] = 'linear'  # ìŠ¤í¬ë˜ì¹˜ ìœ í˜•\n",
        "            elif feature['solidity'] < 0.5:\n",
        "                feature['shape_type'] = 'irregular'  # ë¶ˆê·œì¹™í•œ ì˜¤ì—¼\n",
        "            else:\n",
        "                feature['shape_type'] = 'blob'  # ë´íŠ¸, ì–¼ë£© ë“±\n",
        "\n",
        "            features.append(feature)\n",
        "\n",
        "        return features\n",
        "\n",
        "# ì„¸ê·¸ë©˜í…Œì´ì…˜ ì ìš©\n",
        "segmentor = DefectSegmentation()\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ë‹¤ì–‘í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì ìš©\n",
        "test_img = sample_images[1]\n",
        "\n",
        "# Threshold segmentation\n",
        "thresh_result = segmentor.threshold_segmentation(test_img)\n",
        "\n",
        "# Watershed segmentation\n",
        "watershed_markers, watershed_result = segmentor.watershed_segmentation(test_img)\n",
        "\n",
        "# íŠ¹ì§• ì¶”ì¶œ\n",
        "features = segmentor.extract_defect_features(test_img, thresh_result)\n",
        "\n",
        "# ì‹œê°í™”\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "fig.suptitle('Segmentation Methods for Defect Detection', fontsize=16, fontweight='bold')\n",
        "\n",
        "axes[0, 0].imshow(test_img)\n",
        "axes[0, 0].set_title('Original Image')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(thresh_result, cmap='gray')\n",
        "axes[0, 1].set_title('Threshold Segmentation')\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "axes[0, 2].imshow(watershed_result)\n",
        "axes[0, 2].set_title('Watershed Segmentation')\n",
        "axes[0, 2].axis('off')\n",
        "\n",
        "# Edge detection\n",
        "edges = cv2.Canny(cv2.cvtColor(test_img, cv2.COLOR_RGB2GRAY), 50, 150)\n",
        "axes[1, 0].imshow(edges, cmap='gray')\n",
        "axes[1, 0].set_title('Edge Detection (Canny)')\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "# Morphological operations\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "morph = cv2.morphologyEx(thresh_result, cv2.MORPH_GRADIENT, kernel)\n",
        "axes[1, 1].imshow(morph, cmap='gray')\n",
        "axes[1, 1].set_title('Morphological Gradient')\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "# Feature visualization\n",
        "feature_img = test_img.copy()\n",
        "for feat in features[:5]:  # ìƒìœ„ 5ê°œ íŠ¹ì§•ë§Œ í‘œì‹œ\n",
        "    if 'centroid' in feat:\n",
        "        cy, cx = feat['centroid']\n",
        "        cv2.circle(feature_img, (int(cx), int(cy)), 5, (255, 0, 0), -1)\n",
        "\n",
        "axes[1, 2].imshow(feature_img)\n",
        "axes[1, 2].set_title('Detected Features')\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ“ˆ ì¶”ì¶œëœ ë¶ˆëŸ‰ íŠ¹ì§• (ìƒìœ„ 3ê°œ):\")\n",
        "for i, feat in enumerate(features[:3]):\n",
        "    print(f\"\\në¶ˆëŸ‰ {i+1}:\")\n",
        "    print(f\"  - ë©´ì : {feat.get('area', 0):.0f} pixels\")\n",
        "    print(f\"  - ë‘˜ë ˆ: {feat.get('perimeter', 0):.2f}\")\n",
        "    print(f\"  - í˜•íƒœ: {feat.get('shape_type', 'unknown')}\")\n",
        "    print(f\"  - í¸ì‹¬ë¥ : {feat.get('eccentricity', 0):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIQQ_C-zFD00"
      },
      "source": [
        "## 5. ì˜¤íƒ/ë¯¸íƒ íŠ¸ë ˆì´ë“œì˜¤í”„ ìµœì í™”\n",
        "\n",
        "### 5.1 ì„ê³„ê°’ íŠœë‹ ë° ì„±ëŠ¥ í‰ê°€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IYpbG8tFD00"
      },
      "outputs": [],
      "source": [
        "class ThresholdOptimizer:\n",
        "    def __init__(self):\n",
        "        self.metrics_history = []\n",
        "\n",
        "    def calculate_metrics(self, y_true, y_pred, threshold=0.5):\n",
        "        \"\"\"ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°\"\"\"\n",
        "        # ì´ì§„ ë¶„ë¥˜ë¡œ ë³€í™˜\n",
        "        y_pred_binary = (y_pred >= threshold).astype(int)\n",
        "\n",
        "        # Confusion Matrix\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred_binary).ravel()\n",
        "\n",
        "        # ì£¼ìš” ì§€í‘œ ê³„ì‚°\n",
        "        metrics = {\n",
        "            'threshold': threshold,\n",
        "            'true_positive': tp,\n",
        "            'false_positive': fp,  # ì˜¤íƒ (Type I Error)\n",
        "            'true_negative': tn,\n",
        "            'false_negative': fn,  # ë¯¸íƒ (Type II Error)\n",
        "            'accuracy': (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0,\n",
        "            'precision': tp / (tp + fp) if (tp + fp) > 0 else 0,\n",
        "            'recall': tp / (tp + fn) if (tp + fn) > 0 else 0,  # ê²€ì¶œë¥ \n",
        "            'f1_score': 0,\n",
        "            'false_positive_rate': fp / (fp + tn) if (fp + tn) > 0 else 0,  # ì˜¤íƒë¥ \n",
        "            'false_negative_rate': fn / (fn + tp) if (fn + tp) > 0 else 0   # ë¯¸íƒë¥ \n",
        "        }\n",
        "\n",
        "        # F1 Score\n",
        "        if metrics['precision'] + metrics['recall'] > 0:\n",
        "            metrics['f1_score'] = 2 * (metrics['precision'] * metrics['recall']) / \\\n",
        "                                  (metrics['precision'] + metrics['recall'])\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def optimize_threshold(self, y_true, y_scores, threshold_range=None, optimization_target='f1'):\n",
        "        \"\"\"ìµœì  ì„ê³„ê°’ ì°¾ê¸°\"\"\"\n",
        "        if threshold_range is None:\n",
        "            threshold_range = np.arange(0.1, 0.95, 0.05)\n",
        "\n",
        "        best_threshold = 0.5\n",
        "        best_score = 0\n",
        "\n",
        "        for threshold in threshold_range:\n",
        "            metrics = self.calculate_metrics(y_true, y_scores, threshold)\n",
        "            self.metrics_history.append(metrics)\n",
        "\n",
        "            # ìµœì í™” ëŒ€ìƒì— ë”°ë¥¸ ì ìˆ˜ ê³„ì‚°\n",
        "            if optimization_target == 'f1':\n",
        "                score = metrics['f1_score']\n",
        "            elif optimization_target == 'precision':\n",
        "                score = metrics['precision']\n",
        "            elif optimization_target == 'recall':\n",
        "                score = metrics['recall']\n",
        "            elif optimization_target == 'balanced':\n",
        "                # ì˜¤íƒê³¼ ë¯¸íƒì˜ ê· í˜•\n",
        "                score = 1 - (metrics['false_positive_rate'] + metrics['false_negative_rate']) / 2\n",
        "            else:\n",
        "                score = metrics['accuracy']\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_threshold = threshold\n",
        "\n",
        "        return best_threshold, best_score\n",
        "\n",
        "    def plot_tradeoff_curve(self):\n",
        "        \"\"\"ì˜¤íƒ/ë¯¸íƒ íŠ¸ë ˆì´ë“œì˜¤í”„ ì»¤ë¸Œ ì‹œê°í™”\"\"\"\n",
        "        if not self.metrics_history:\n",
        "            print(\"No metrics history available\")\n",
        "            return\n",
        "\n",
        "        df = pd.DataFrame(self.metrics_history)\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "        fig.suptitle('Threshold Optimization Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # 1. Precision vs Recall\n",
        "        axes[0, 0].plot(df['threshold'], df['precision'], 'b-', label='Precision', linewidth=2)\n",
        "        axes[0, 0].plot(df['threshold'], df['recall'], 'r-', label='Recall', linewidth=2)\n",
        "        axes[0, 0].plot(df['threshold'], df['f1_score'], 'g--', label='F1 Score', linewidth=2)\n",
        "        axes[0, 0].set_xlabel('Threshold')\n",
        "        axes[0, 0].set_ylabel('Score')\n",
        "        axes[0, 0].set_title('Precision, Recall, and F1 Score vs Threshold')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 2. False Positive vs False Negative\n",
        "        axes[0, 1].plot(df['threshold'], df['false_positive_rate'], 'orange',\n",
        "                       label='False Positive Rate (ì˜¤íƒë¥ )', linewidth=2)\n",
        "        axes[0, 1].plot(df['threshold'], df['false_negative_rate'], 'purple',\n",
        "                       label='False Negative Rate (ë¯¸íƒë¥ )', linewidth=2)\n",
        "        axes[0, 1].set_xlabel('Threshold')\n",
        "        axes[0, 1].set_ylabel('Error Rate')\n",
        "        axes[0, 1].set_title('ì˜¤íƒë¥  vs ë¯¸íƒë¥ ')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. ROC-like curve (FPR vs TPR)\n",
        "        tpr = df['recall']  # True Positive Rate = Recall\n",
        "        fpr = df['false_positive_rate']\n",
        "        axes[1, 0].plot(fpr, tpr, 'b-', linewidth=2)\n",
        "        axes[1, 0].plot([0, 1], [0, 1], 'r--', alpha=0.5)\n",
        "        axes[1, 0].set_xlabel('False Positive Rate')\n",
        "        axes[1, 0].set_ylabel('True Positive Rate')\n",
        "        axes[1, 0].set_title('ROC-like Curve')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. Cost Analysis\n",
        "        # ë¹„ìš© ê°€ì •: ì˜¤íƒ ë¹„ìš© = 1, ë¯¸íƒ ë¹„ìš© = 10 (ë¯¸íƒì´ ë” ë¹„ì‹¸ë‹¤ê³  ê°€ì •)\n",
        "        cost_fp = 1  # ì˜¤íƒ ë¹„ìš©\n",
        "        cost_fn = 10  # ë¯¸íƒ ë¹„ìš©\n",
        "\n",
        "        total_cost = df['false_positive'] * cost_fp + df['false_negative'] * cost_fn\n",
        "        axes[1, 1].plot(df['threshold'], total_cost, 'r-', linewidth=2)\n",
        "        axes[1, 1].set_xlabel('Threshold')\n",
        "        axes[1, 1].set_ylabel('Total Cost')\n",
        "        axes[1, 1].set_title(f'Cost Analysis (FP cost={cost_fp}, FN cost={cost_fn})')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # ìµœì ì  í‘œì‹œ\n",
        "        optimal_idx = df['f1_score'].idxmax()\n",
        "        optimal_threshold = df.loc[optimal_idx, 'threshold']\n",
        "\n",
        "        for ax in axes.flat:\n",
        "            ax.axvline(x=optimal_threshold, color='green', linestyle=':',\n",
        "                      alpha=0.7, label=f'Optimal ({optimal_threshold:.2f})')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return df\n",
        "\n",
        "# ì„ê³„ê°’ ìµœì í™” ì‹œë®¬ë ˆì´ì…˜\n",
        "np.random.seed(42)\n",
        "\n",
        "# ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±\n",
        "n_samples = 1000\n",
        "y_true = np.random.randint(0, 2, n_samples)  # ì‹¤ì œ ë¼ë²¨ (0: ì •ìƒ, 1: ë¶ˆëŸ‰)\n",
        "y_scores = np.random.beta(2, 5, n_samples)  # ëª¨ë¸ì˜ ì‹ ë¢°ë„ ì ìˆ˜\n",
        "y_scores[y_true == 1] += np.random.normal(0.3, 0.1, sum(y_true == 1))  # ë¶ˆëŸ‰í’ˆì€ ë†’ì€ ì ìˆ˜\n",
        "y_scores = np.clip(y_scores, 0, 1)\n",
        "\n",
        "# ìµœì í™” ì‹¤í–‰\n",
        "optimizer = ThresholdOptimizer()\n",
        "\n",
        "# ë‹¤ì–‘í•œ ìµœì í™” ëª©í‘œë¡œ í…ŒìŠ¤íŠ¸\n",
        "optimization_targets = ['f1', 'precision', 'recall', 'balanced']\n",
        "\n",
        "print(\"ğŸ¯ ì„ê³„ê°’ ìµœì í™” ê²°ê³¼:\\n\")\n",
        "for target in optimization_targets:\n",
        "    best_threshold, best_score = optimizer.optimize_threshold(\n",
        "        y_true, y_scores, optimization_target=target\n",
        "    )\n",
        "    print(f\"ëª©í‘œ: {target:10s} | ìµœì  ì„ê³„ê°’: {best_threshold:.3f} | ì ìˆ˜: {best_score:.3f}\")\n",
        "\n",
        "# íŠ¸ë ˆì´ë“œì˜¤í”„ ê³¡ì„  ì‹œê°í™”\n",
        "metrics_df = optimizer.plot_tradeoff_curve()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJpgB6kKFD01"
      },
      "source": [
        "### 5.2 ì‹¤ì „ ìµœì í™” ì „ëµ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NjpFsK8FD01"
      },
      "outputs": [],
      "source": [
        "class ProductionOptimizationStrategy:\n",
        "    def __init__(self):\n",
        "        self.strategies = {\n",
        "            'conservative': {\n",
        "                'description': 'ë¯¸íƒ ìµœì†Œí™” (ê³ í’ˆì§ˆ ìš”êµ¬)',\n",
        "                'threshold': 0.3,\n",
        "                'use_case': 'ì˜ë£Œê¸°ê¸°, ìë™ì°¨ ì•ˆì „ë¶€í’ˆ'\n",
        "            },\n",
        "            'balanced': {\n",
        "                'description': 'ê· í˜•ì¡íŒ ì ‘ê·¼',\n",
        "                'threshold': 0.5,\n",
        "                'use_case': 'ì¼ë°˜ ì œì¡°ì—…'\n",
        "            },\n",
        "            'aggressive': {\n",
        "                'description': 'ì˜¤íƒ ìµœì†Œí™” (ë¹„ìš© ì ˆê°)',\n",
        "                'threshold': 0.7,\n",
        "                'use_case': 'ì €ê°€ ëŒ€ëŸ‰ìƒì‚° ì œí’ˆ'\n",
        "            },\n",
        "            'dynamic': {\n",
        "                'description': 'ì‹¤ì‹œê°„ ì¡°ì •',\n",
        "                'threshold': 'adaptive',\n",
        "                'use_case': 'ë³€ë™ì„± ë†’ì€ ìƒì‚° ë¼ì¸'\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def recommend_strategy(self, product_info):\n",
        "        \"\"\"ì œí’ˆ íŠ¹ì„±ì— ë”°ë¥¸ ì „ëµ ì¶”ì²œ\"\"\"\n",
        "        defect_cost = product_info.get('defect_cost', 'medium')\n",
        "        production_volume = product_info.get('volume', 'medium')\n",
        "        quality_requirement = product_info.get('quality', 'medium')\n",
        "\n",
        "        if quality_requirement == 'critical' or defect_cost == 'very_high':\n",
        "            return 'conservative'\n",
        "        elif production_volume == 'very_high' and defect_cost == 'low':\n",
        "            return 'aggressive'\n",
        "        elif production_volume == 'variable':\n",
        "            return 'dynamic'\n",
        "        else:\n",
        "            return 'balanced'\n",
        "\n",
        "    def calculate_business_impact(self, metrics, production_info):\n",
        "        \"\"\"ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ë„ ê³„ì‚°\"\"\"\n",
        "        daily_production = production_info.get('daily_volume', 10000)\n",
        "        unit_price = production_info.get('unit_price', 100)\n",
        "        defect_cost_multiplier = production_info.get('defect_multiplier', 10)\n",
        "        inspection_cost = production_info.get('inspection_cost', 1)\n",
        "\n",
        "        # ì¼ì¼ ë¹„ìš© ê³„ì‚°\n",
        "        false_positives = metrics['false_positive_rate'] * daily_production\n",
        "        false_negatives = metrics['false_negative_rate'] * daily_production\n",
        "\n",
        "        # ì˜¤íƒ ë¹„ìš©: ì¬ê²€ì‚¬ ë¹„ìš© + ìƒì‚° ì§€ì—°\n",
        "        fp_cost = false_positives * inspection_cost * 2\n",
        "\n",
        "        # ë¯¸íƒ ë¹„ìš©: ë¶ˆëŸ‰í’ˆ ì¶œí•˜ë¡œ ì¸í•œ ì†ì‹¤\n",
        "        fn_cost = false_negatives * unit_price * defect_cost_multiplier\n",
        "\n",
        "        total_cost = fp_cost + fn_cost\n",
        "\n",
        "        return {\n",
        "            'daily_false_positives': int(false_positives),\n",
        "            'daily_false_negatives': int(false_negatives),\n",
        "            'false_positive_cost': fp_cost,\n",
        "            'false_negative_cost': fn_cost,\n",
        "            'total_daily_cost': total_cost,\n",
        "            'annual_cost': total_cost * 250  # ì—°ê°„ ì‘ì—…ì¼ 250ì¼ ê°€ì •\n",
        "        }\n",
        "\n",
        "# ì‹¤ì „ ìµœì í™” ì „ëµ ì‹œë®¬ë ˆì´ì…˜\n",
        "strategy_optimizer = ProductionOptimizationStrategy()\n",
        "\n",
        "# ë‹¤ì–‘í•œ ì œí’ˆ ì‹œë‚˜ë¦¬ì˜¤\n",
        "product_scenarios = [\n",
        "    {\n",
        "        'name': 'ì˜ë£Œìš© ì„í”Œë€íŠ¸',\n",
        "        'defect_cost': 'very_high',\n",
        "        'volume': 'low',\n",
        "        'quality': 'critical',\n",
        "        'daily_volume': 100,\n",
        "        'unit_price': 10000,\n",
        "        'defect_multiplier': 100,\n",
        "        'inspection_cost': 50\n",
        "    },\n",
        "    {\n",
        "        'name': 'ìŠ¤ë§ˆíŠ¸í° ì¼€ì´ìŠ¤',\n",
        "        'defect_cost': 'low',\n",
        "        'volume': 'very_high',\n",
        "        'quality': 'medium',\n",
        "        'daily_volume': 50000,\n",
        "        'unit_price': 10,\n",
        "        'defect_multiplier': 3,\n",
        "        'inspection_cost': 0.1\n",
        "    },\n",
        "    {\n",
        "        'name': 'ìë™ì°¨ ë¸Œë ˆì´í¬ íŒ¨ë“œ',\n",
        "        'defect_cost': 'high',\n",
        "        'volume': 'medium',\n",
        "        'quality': 'high',\n",
        "        'daily_volume': 5000,\n",
        "        'unit_price': 500,\n",
        "        'defect_multiplier': 50,\n",
        "        'inspection_cost': 5\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"ğŸ­ ì œí’ˆë³„ ìµœì í™” ì „ëµ ì¶”ì²œ:\\n\")\n",
        "for product in product_scenarios:\n",
        "    recommended = strategy_optimizer.recommend_strategy(product)\n",
        "    strategy = strategy_optimizer.strategies[recommended]\n",
        "\n",
        "    print(f\"ğŸ“¦ {product['name']}:\")\n",
        "    print(f\"   ì¶”ì²œ ì „ëµ: {recommended} - {strategy['description']}\")\n",
        "    print(f\"   ê¶Œì¥ ì„ê³„ê°’: {strategy['threshold']}\")\n",
        "    print(f\"   ì ìš© ì‚¬ë¡€: {strategy['use_case']}\")\n",
        "\n",
        "    # ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ë„ ê³„ì‚° (ì˜ˆì‹œ ë©”íŠ¸ë¦­ ì‚¬ìš©)\n",
        "    sample_metrics = {\n",
        "        'false_positive_rate': 0.02 if recommended == 'aggressive' else 0.05,\n",
        "        'false_negative_rate': 0.05 if recommended == 'conservative' else 0.01\n",
        "    }\n",
        "\n",
        "    impact = strategy_optimizer.calculate_business_impact(sample_metrics, product)\n",
        "\n",
        "    print(f\"   ì˜ˆìƒ ì¼ì¼ ì˜¤íƒ: {impact['daily_false_positives']} ê°œ\")\n",
        "    print(f\"   ì˜ˆìƒ ì¼ì¼ ë¯¸íƒ: {impact['daily_false_negatives']} ê°œ\")\n",
        "    print(f\"   ì¼ì¼ ì´ ë¹„ìš©: ${impact['total_daily_cost']:,.0f}\")\n",
        "    print(f\"   ì—°ê°„ ë¹„ìš©: ${impact['annual_cost']:,.0f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "equJJmK7FD01"
      },
      "source": [
        "## 6. ì‹¤ìŠµ ê³¼ì œ ë° ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "### Session 2 ì‹¤ìŠµ ê³¼ì œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcFwvDUVFD01"
      },
      "outputs": [],
      "source": [
        "# ì‹¤ìŠµ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "def create_practice_checklist():\n",
        "    checklist = {\n",
        "        'ë°ì´í„° ìˆ˜ì§‘': [\n",
        "            'ë¶ˆëŸ‰ ìƒ˜í”Œ ì´ë¯¸ì§€ ìµœì†Œ 100ì¥ ìˆ˜ì§‘',\n",
        "            'ì •ìƒ ìƒ˜í”Œ ì´ë¯¸ì§€ ìµœì†Œ 300ì¥ ìˆ˜ì§‘',\n",
        "            'ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´ì—ì„œ ì´¬ì˜',\n",
        "            'ì¼ê´€ëœ í•´ìƒë„ì™€ í¬ë§· ìœ ì§€'\n",
        "        ],\n",
        "        'ë¼ë²¨ë§': [\n",
        "            'ë¼ë²¨ë§ ê°€ì´ë“œë¼ì¸ ë¬¸ì„œ ì‘ì„±',\n",
        "            'ìµœì†Œ 2ëª…ì˜ ë¼ë²¨ëŸ¬ë¡œ êµì°¨ ê²€ì¦',\n",
        "            'IoU > 0.5 ì´ìƒ ì¼ì¹˜ë„ í™•ë³´',\n",
        "            'ê° ë¶ˆëŸ‰ ìœ í˜•ë³„ ìµœì†Œ 20ê°œ ìƒ˜í”Œ'\n",
        "        ],\n",
        "        'ëª¨ë¸ í•™ìŠµ': [\n",
        "            'YOLO ëª¨ë¸ ì „ì´í•™ìŠµ ìˆ˜í–‰',\n",
        "            'Train/Val/Test ë¶„í•  (6:2:2)',\n",
        "            'ìµœì†Œ 50 epoch í•™ìŠµ',\n",
        "            'mAP > 0.7 ë‹¬ì„±'\n",
        "        ],\n",
        "        'ìµœì í™”': [\n",
        "            'ì œí’ˆë³„ ë¹„ìš© ë§¤íŠ¸ë¦­ìŠ¤ ì‘ì„±',\n",
        "            'ì„ê³„ê°’ ê·¸ë¦¬ë“œ ì„œì¹˜ ìˆ˜í–‰',\n",
        "            'ì˜¤íƒ/ë¯¸íƒ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„',\n",
        "            'A/B í…ŒìŠ¤íŠ¸ ê³„íš ìˆ˜ë¦½'\n",
        "        ],\n",
        "        'ë°°í¬ ì¤€ë¹„': [\n",
        "            'ì¶”ë¡  ì†ë„ ì¸¡ì • (FPS)',\n",
        "            'Edge ë””ë°”ì´ìŠ¤ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸',\n",
        "            'ëª¨ë¸ ê²½ëŸ‰í™” (Quantization)',\n",
        "            'ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ êµ¬ì„±'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return checklist\n",
        "\n",
        "# ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
        "checklist = create_practice_checklist()\n",
        "\n",
        "print(\"âœ… ë¹„ì „ ë¶ˆëŸ‰ê²€ì‚¬ êµ¬ì¶• ì²´í¬ë¦¬ìŠ¤íŠ¸\\n\")\n",
        "for category, items in checklist.items():\n",
        "    print(f\"ğŸ“Œ {category}:\")\n",
        "    for item in items:\n",
        "        print(f\"   â–¡ {item}\")\n",
        "    print()\n",
        "\n",
        "# ì‹¤ìŠµ ê³¼ì œ í…œí”Œë¦¿ ì €ì¥\n",
        "practice_template = {\n",
        "    'project_info': {\n",
        "        'product_name': '',\n",
        "        'defect_types': [],\n",
        "        'current_inspection_method': '',\n",
        "        'target_metrics': {\n",
        "            'detection_rate': 0,\n",
        "            'false_positive_rate': 0,\n",
        "            'inspection_time': 0\n",
        "        }\n",
        "    },\n",
        "    'data_collection': {\n",
        "        'camera_specs': {},\n",
        "        'lighting_setup': '',\n",
        "        'total_images': 0,\n",
        "        'labeling_tool': ''\n",
        "    },\n",
        "    'model_performance': {\n",
        "        'mAP50': 0,\n",
        "        'inference_time': 0,\n",
        "        'optimal_threshold': 0\n",
        "    },\n",
        "    'roi_analysis': {\n",
        "        'implementation_cost': 0,\n",
        "        'annual_savings': 0,\n",
        "        'payback_period': 0\n",
        "    }\n",
        "}\n",
        "\n",
        "# JSON íŒŒì¼ë¡œ ì €ì¥\n",
        "with open('vision_inspection_template.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(practice_template, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\nğŸ’¾ ì‹¤ìŠµ í…œí”Œë¦¿ì´ 'vision_inspection_template.json'ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "print(\"ğŸ“ ê·€ì‚¬ì˜ ì‹¤ì œ ë°ì´í„°ë¡œ ì±„ì›Œì£¼ì„¸ìš”.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOtzBmMXFD01"
      },
      "source": [
        "## 7. Session 2 í•µì‹¬ ìš”ì•½\n",
        "\n",
        "### ì´ë²ˆ ì„¸ì…˜ì—ì„œ í•™ìŠµí•œ ë‚´ìš©:\n",
        "\n",
        "1. **ë°ì´í„° ìˆ˜ì§‘ ë° í’ˆì§ˆ ê´€ë¦¬**\n",
        "   - ì¡°ëª… ì„¤ì •ì˜ ì¤‘ìš”ì„± (Front, Back, Coaxial, Ring, Dome)\n",
        "   - ë¼ë²¨ë§ í’ˆì§ˆ ê´€ë¦¬ (ì¼ê´€ì„±, ì™„ì „ì„±, ì •í™•ì„±)\n",
        "   - Inter-annotator agreement ì¸¡ì •\n",
        "\n",
        "2. **YOLO ëª¨ë¸ í™œìš©**\n",
        "   - ì „ì´í•™ìŠµì„ í†µí•œ ë¹ ë¥¸ í•™ìŠµ\n",
        "   - ë°ì´í„° í¬ë§· ë³€í™˜ ë° ì¦ê°•\n",
        "   - ëª¨ë¸ í¬ê¸°ë³„ ì„±ëŠ¥/ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„\n",
        "\n",
        "3. **ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ë²•**\n",
        "   - Threshold, Watershed ë“± ì „í†µì  ë°©ë²•\n",
        "   - ë¶ˆëŸ‰ íŠ¹ì§• ì¶”ì¶œ (ë©´ì , ë‘˜ë ˆ, í¸ì‹¬ë¥  ë“±)\n",
        "   - í˜•íƒœ ê¸°ë°˜ ë¶ˆëŸ‰ ë¶„ë¥˜\n",
        "\n",
        "4. **ì„ê³„ê°’ ìµœì í™”**\n",
        "   - ì˜¤íƒ/ë¯¸íƒ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„\n",
        "   - ì œí’ˆë³„ ìµœì í™” ì „ëµ ìˆ˜ë¦½\n",
        "   - ë¹„ì¦ˆë‹ˆìŠ¤ ì˜í–¥ë„ ê³„ì‚°\n",
        "\n",
        "### ì‹¤ì „ ì ìš© íŒ:\n",
        "- ì´ˆê¸°ì—ëŠ” ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ì ì§„ì  í™•ëŒ€\n",
        "- í˜„ì¥ ì‘ì—…ìì™€ ê¸´ë°€í•œ í˜‘ì—…ìœ¼ë¡œ ì‹¤ìš©ì  ìš”êµ¬ì‚¬í•­ íŒŒì•…\n",
        "- ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ê³¼ ì¬í•™ìŠµ ì²´ê³„ êµ¬ì¶•\n",
        "- Edge ë°°í¬ë¥¼ ê³ ë ¤í•œ ëª¨ë¸ ê²½ëŸ‰í™”\n",
        "\n",
        "### ë‹¤ìŒ ì„¸ì…˜ ì˜ˆê³ :\n",
        "**Session 3: ì˜ˆì§€ë³´ì „(ì‹œê³„ì—´) ì‹¬í™” (4-6ì‹œê°„)**\n",
        "- FFT ë° í†µê³„ í”¼ì²˜ ì¶”ì¶œ\n",
        "- Isolation Forest vs LSTM/AutoEncoder\n",
        "- ì‹¤ì‹œê°„ ì´ìƒ íƒì§€ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLAQQXQTFD01"
      },
      "outputs": [],
      "source": [
        "print(\"ğŸ¯ Session 2 ì™„ë£Œ!\")\n",
        "print(\"\\në‹¤ìŒ ì„¸ì…˜ ì¤€ë¹„ì‚¬í•­:\")\n",
        "print(\"1. ì„¤ë¹„ ì„¼ì„œ ë°ì´í„° (ì§„ë™, ì˜¨ë„, ì „ë¥˜ ë“±) ì¤€ë¹„\")\n",
        "print(\"2. ê³ ì¥ ì´ë ¥ ë°ì´í„° ìˆ˜ì§‘\")\n",
        "print(\"3. ì •ìƒ/ë¹„ì •ìƒ ìš´ì „ ì¡°ê±´ ì •ì˜\")\n",
        "print(\"\\nğŸ’¡ ì‹¤ìŠµ ì¤‘ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ì£¼ì„¸ìš”!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}